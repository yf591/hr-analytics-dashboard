{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0376e486",
   "metadata": {},
   "source": [
    "# 機械学習モデル比較分析\n",
    "\n",
    "このノートブックでは、HRアナリティクスデータに対して複数の機械学習モデル（RandomForest、XGBoost、LightGBM）を適用し、それらのパフォーマンスを比較します。最適なモデルを特定し、UIで使用するための基盤を提供します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca41567",
   "metadata": {},
   "source": [
    "## 必要なライブラリのインポート\n",
    "\n",
    "まず、分析に必要なライブラリをインポートします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8886877d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ操作・可視化ライブラリ\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# 機械学習ライブラリ\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve\n",
    "\n",
    "# XGBoost、LightGBMライブラリ\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# 警告を無視\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# プロット設定\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44001bcc",
   "metadata": {},
   "source": [
    "## データの読み込み\n",
    "\n",
    "プロジェクトのデータローダーを使用してHRデータを読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b429b105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# プロジェクトのモジュールにアクセスできるようにパスを追加\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../..'))\n",
    "\n",
    "# データローダーのインポート\n",
    "from src.data.loader import load_hr_data\n",
    "\n",
    "# HRデータの読み込み\n",
    "df = load_hr_data()\n",
    "\n",
    "# データの確認\n",
    "print(f\"データサイズ: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a73b87b",
   "metadata": {},
   "source": [
    "## 離職予測モデルの比較\n",
    "\n",
    "離職予測（Attrition）のための異なる機械学習モデルを実装し、その性能を比較します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37248ec",
   "metadata": {},
   "source": [
    "### データの前処理\n",
    "\n",
    "モデルのトレーニングに使用する特徴量と目的変数を準備します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b332c144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 離職予測に使用する特徴量\n",
    "features = [\n",
    "    'Age', 'MonthlyIncome', 'DistanceFromHome', 'OverTime',\n",
    "    'JobSatisfaction', 'WorkLifeBalance', 'YearsAtCompany',\n",
    "    'YearsSinceLastPromotion', 'JobLevel', 'MaritalStatus',\n",
    "    'NumCompaniesWorked', 'TrainingTimesLastYear', 'BusinessTravel'\n",
    "]\n",
    "\n",
    "# 目的変数\n",
    "target = 'Attrition'\n",
    "\n",
    "# データの準備\n",
    "X = df[features].copy()\n",
    "y = df[target].copy()\n",
    "\n",
    "# カテゴリ変数とカテゴリでない変数の分類\n",
    "categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "print(f\"カテゴリ変数: {categorical_features}\")\n",
    "print(f\"数値変数: {numeric_features}\")\n",
    "\n",
    "# データの分割（訓練用データとテスト用データ）\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 前処理パイプラインの定義\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825e3398",
   "metadata": {},
   "source": [
    "### モデルの定義\n",
    "\n",
    "比較するモデルの定義とパイプラインの構築を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b003332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの定義\n",
    "models = {\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'XGBoost': xgb.XGBClassifier(n_estimators=100, random_state=42),\n",
    "    'LightGBM': lgb.LGBMClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# 結果格納用の辞書\n",
    "model_results = {}\n",
    "model_predictions = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf5b858",
   "metadata": {},
   "source": [
    "### モデルのトレーニングと評価\n",
    "\n",
    "各モデルをトレーニングし、テストデータでの性能を評価します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcf6c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各モデルでの学習と評価\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\n{model_name}のトレーニングと評価中...\")\n",
    "    \n",
    "    # モデルパイプラインの作成\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "    \n",
    "    # モデルの学習\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # テストデータでの予測\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    y_prob = pipeline.predict_proba(X_test)[:, 1]  # 離職確率（陽性クラスの確率）\n",
    "    \n",
    "    # モデル性能の評価\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_prob)\n",
    "    \n",
    "    # 結果の格納\n",
    "    model_results[model_name] = {\n",
    "        'accuracy': accuracy,\n",
    "        'roc_auc': roc_auc,\n",
    "        'pipeline': pipeline\n",
    "    }\n",
    "    \n",
    "    model_predictions[model_name] = {\n",
    "        'y_pred': y_pred,\n",
    "        'y_prob': y_prob\n",
    "    }\n",
    "    \n",
    "    # 結果の表示\n",
    "    print(f\"{model_name}の精度: {accuracy:.4f}\")\n",
    "    print(f\"{model_name}のROC-AUC: {roc_auc:.4f}\")\n",
    "    print(f\"\\n分類レポート:\\n{classification_report(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f12029",
   "metadata": {},
   "source": [
    "### モデルパフォーマンスの比較\n",
    "\n",
    "各モデルの性能を視覚的に比較します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd706eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル性能の比較（精度とROC-AUC）\n",
    "performance_df = pd.DataFrame({\n",
    "    'モデル': list(model_results.keys()),\n",
    "    '精度': [results['accuracy'] for results in model_results.values()],\n",
    "    'ROC-AUC': [results['roc_auc'] for results in model_results.values()]\n",
    "})\n",
    "\n",
    "# データを長形式に変換\n",
    "performance_long = performance_df.melt(id_vars=['モデル'], var_name='評価指標', value_name='スコア')\n",
    "\n",
    "# バープロット\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='モデル', y='スコア', hue='評価指標', data=performance_long)\n",
    "plt.title('各モデルの性能比較', fontsize=15)\n",
    "plt.ylim(0, 1)\n",
    "plt.ylabel('スコア')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a722442",
   "metadata": {},
   "source": [
    "### ROC曲線の比較\n",
    "\n",
    "各モデルのROC曲線を比較し、識別性能を評価します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fd7c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC曲線の比較\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for model_name, predictions in model_predictions.items():\n",
    "    fpr, tpr, _ = roc_curve(y_test, predictions['y_prob'], pos_label=\"Yes\")\n",
    "    roc_auc = model_results[model_name]['roc_auc']\n",
    "    plt.plot(fpr, tpr, lw=2, label=f'{model_name} (AUC = {roc_auc:.3f})')\n",
    "\n",
    "# ランダム分類器のROC曲線（参照用）\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='ランダム分類器')\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('偽陽性率')\n",
    "plt.ylabel('真陽性率')\n",
    "plt.title('各モデルのROC曲線比較', fontsize=15)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8709bf0e",
   "metadata": {},
   "source": [
    "### 特徴量重要度の比較\n",
    "\n",
    "各モデルの特徴量重要度を比較し、離職予測に最も影響する要因を分析します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494e4f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴量名の取得\n",
    "preprocessor = model_results['RandomForest']['pipeline'].named_steps['preprocessor']\n",
    "feature_names = list(preprocessor.get_feature_names_out())\n",
    "\n",
    "# 各モデルの特徴量重要度を取得\n",
    "feature_importances = {}\n",
    "\n",
    "for model_name, results in model_results.items():\n",
    "    pipeline = results['pipeline']\n",
    "    model = pipeline.named_steps['classifier']\n",
    "    \n",
    "    # モデル種類によって重要度の取得方法が異なる\n",
    "    try:\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            importances = model.feature_importances_\n",
    "        elif model_name == 'XGBoost':\n",
    "            # XGBoostの場合\n",
    "            importances = model.get_booster().get_score(importance_type='weight')\n",
    "            # 特徴名のマッピングが必要な場合がある\n",
    "            if isinstance(importances, dict):\n",
    "                # 辞書から配列に変換\n",
    "                feat_importances = np.zeros(len(feature_names))\n",
    "                for feat, imp in importances.items():\n",
    "                    # 特徴名のインデックスを見つける\n",
    "                    try:\n",
    "                        idx = feature_names.index(feat)\n",
    "                        feat_importances[idx] = imp\n",
    "                    except ValueError:\n",
    "                        # 特徴名が一致しない場合はスキップ\n",
    "                        pass\n",
    "                importances = feat_importances\n",
    "        else:\n",
    "            # その他の方法で特徴量重要度を取得\n",
    "            importances = np.zeros(len(feature_names))\n",
    "            print(f\"{model_name}の特徴量重要度が取得できません\")\n",
    "            \n",
    "        # 長さをチェック\n",
    "        if len(importances) == len(feature_names):\n",
    "            feature_importances[model_name] = importances\n",
    "        else:\n",
    "            print(f\"{model_name}の特徴量重要度の長さが一致しません: {len(importances)} vs {len(feature_names)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"{model_name}の特徴量重要度取得中にエラー: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd977725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestの特徴量重要度を可視化\n",
    "if 'RandomForest' in feature_importances:\n",
    "    # 特徴量重要度をデータフレームに変換\n",
    "    rf_importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': feature_importances['RandomForest']\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    # 上位15個の特徴量のみ表示\n",
    "    top_features = rf_importance_df.head(15)\n",
    "    \n",
    "    # プロット\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(x='Importance', y='Feature', data=top_features)\n",
    "    plt.title('RandomForest: 特徴量重要度（上位15）', fontsize=15)\n",
    "    plt.xlabel('重要度')\n",
    "    plt.ylabel('特徴量')\n",
    "    plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a40bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoostの特徴量重要度を可視化\n",
    "if 'XGBoost' in feature_importances and len(feature_importances['XGBoost']) > 0:\n",
    "    # 特徴量重要度をデータフレームに変換\n",
    "    xgb_importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': feature_importances['XGBoost']\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    # 上位15個の特徴量のみ表示\n",
    "    top_features = xgb_importance_df.head(15)\n",
    "    \n",
    "    # プロット\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(x='Importance', y='Feature', data=top_features)\n",
    "    plt.title('XGBoost: 特徴量重要度（上位15）', fontsize=15)\n",
    "    plt.xlabel('重要度')\n",
    "    plt.ylabel('特徴量')\n",
    "    plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9175eb82",
   "metadata": {},
   "source": [
    "## 給与予測モデルの比較\n",
    "\n",
    "給与予測のための異なる回帰モデルを実装し、その性能を比較します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a845cf2a",
   "metadata": {},
   "source": [
    "### データの前処理\n",
    "\n",
    "給与予測モデルに使用するデータを準備します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5897ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 給与予測に使用する特徴量\n",
    "salary_features = [\n",
    "    'JobLevel', 'Age', 'YearsAtCompany', 'TotalWorkingYears',\n",
    "    'Department', 'JobRole', 'EducationField', 'Education',\n",
    "    'PerformanceRating', 'Gender'\n",
    "]\n",
    "\n",
    "# 目的変数\n",
    "salary_target = 'MonthlyIncome'\n",
    "\n",
    "# 欠損値のないレコードだけ使用\n",
    "salary_df = df[salary_features + [salary_target]].dropna()\n",
    "\n",
    "# データの分割\n",
    "X_salary = salary_df[salary_features]\n",
    "y_salary = salary_df[salary_target]\n",
    "\n",
    "# カテゴリ変数とカテゴリでない変数の分類\n",
    "salary_cat_features = X_salary.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "salary_num_features = X_salary.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "print(f\"カテゴリ変数: {salary_cat_features}\")\n",
    "print(f\"数値変数: {salary_num_features}\")\n",
    "\n",
    "# データの分割（訓練用データとテスト用データ）\n",
    "X_train_salary, X_test_salary, y_train_salary, y_test_salary = train_test_split(\n",
    "    X_salary, y_salary, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# 前処理パイプラインの定義\n",
    "salary_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), salary_num_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), salary_cat_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b80c58b",
   "metadata": {},
   "source": [
    "### 回帰モデルの定義\n",
    "\n",
    "給与予測のための回帰モデルを定義します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f121112b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "# 回帰モデルの定義\n",
    "regression_models = {\n",
    "    'RandomForest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'XGBoost': xgb.XGBRegressor(n_estimators=100, random_state=42),\n",
    "    'LightGBM': lgb.LGBMRegressor(n_estimators=100, random_state=42),\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'GradientBoosting': GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# 結果格納用の辞書\n",
    "regression_results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53c8b7d",
   "metadata": {},
   "source": [
    "### 回帰モデルのトレーニングと評価\n",
    "\n",
    "各回帰モデルをトレーニングし、テストデータでの性能を評価します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce1cbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各モデルでの学習と評価\n",
    "for model_name, model in regression_models.items():\n",
    "    print(f\"\\n{model_name}のトレーニングと評価中...\")\n",
    "    \n",
    "    # モデルパイプラインの作成\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', salary_preprocessor),\n",
    "        ('regressor', model)\n",
    "    ])\n",
    "    \n",
    "    # モデルの学習\n",
    "    pipeline.fit(X_train_salary, y_train_salary)\n",
    "    \n",
    "    # テストデータでの予測\n",
    "    y_pred_salary = pipeline.predict(X_test_salary)\n",
    "    \n",
    "    # モデル性能の評価\n",
    "    r2 = r2_score(y_test_salary, y_pred_salary)\n",
    "    mae = mean_absolute_error(y_test_salary, y_pred_salary)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_salary, y_pred_salary))\n",
    "    \n",
    "    # 結果の格納\n",
    "    regression_results[model_name] = {\n",
    "        'r2': r2,\n",
    "        'mae': mae,\n",
    "        'rmse': rmse,\n",
    "        'pipeline': pipeline,\n",
    "        'predictions': y_pred_salary\n",
    "    }\n",
    "    \n",
    "    # 結果の表示\n",
    "    print(f\"{model_name}のR²スコア: {r2:.4f}\")\n",
    "    print(f\"{model_name}のMAE: {mae:.2f}\")\n",
    "    print(f\"{model_name}のRMSE: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a27ffdc",
   "metadata": {},
   "source": [
    "### 回帰モデルのパフォーマンス比較\n",
    "\n",
    "各回帰モデルの性能を視覚的に比較します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437805d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル性能の比較（R²、MAE、RMSE）\n",
    "regression_performance_df = pd.DataFrame({\n",
    "    'モデル': list(regression_results.keys()),\n",
    "    'R²': [results['r2'] for results in regression_results.values()],\n",
    "    'MAE': [results['mae'] for results in regression_results.values()],\n",
    "    'RMSE': [results['rmse'] for results in regression_results.values()]\n",
    "})\n",
    "\n",
    "# R²スコアを可視化\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='モデル', y='R²', data=regression_performance_df, palette='viridis')\n",
    "plt.title('各モデルのR²スコア比較', fontsize=15)\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "for i, v in enumerate(regression_performance_df['R²']):\n",
    "    plt.text(i, v + 0.01, f\"{v:.3f}\", ha='center', fontsize=10)\n",
    "plt.show()\n",
    "\n",
    "# MAEとRMSEを可視化\n",
    "error_df = regression_performance_df.melt(id_vars=['モデル'], value_vars=['MAE', 'RMSE'], var_name='評価指標', value_name='誤差')\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.barplot(x='モデル', y='誤差', hue='評価指標', data=error_df, palette='Set2')\n",
    "plt.title('各モデルの誤差指標比較', fontsize=15)\n",
    "plt.ylabel('誤差値')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f835a9",
   "metadata": {},
   "source": [
    "### 予測値と実際値の比較\n",
    "\n",
    "最も性能の良いモデルについて、予測値と実際値を散布図で比較します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9df00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R²スコアで最良のモデルを選択\n",
    "best_model = regression_performance_df.loc[regression_performance_df['R²'].idxmax(), 'モデル']\n",
    "print(f\"最良のモデル: {best_model}（R²: {regression_results[best_model]['r2']:.4f}）\")\n",
    "\n",
    "# 予測値と実際値の散布図\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(y_test_salary, regression_results[best_model]['predictions'], alpha=0.5)\n",
    "plt.plot([y_test_salary.min(), y_test_salary.max()], [y_test_salary.min(), y_test_salary.max()], 'r--')\n",
    "plt.xlabel('実際の月収')\n",
    "plt.ylabel('予測された月収')\n",
    "plt.title(f'{best_model}: 予測値 vs 実際値', fontsize=15)\n",
    "plt.grid(linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bc562b",
   "metadata": {},
   "source": [
    "## 結論とモデル選択\n",
    "\n",
    "各タスクに最適なモデルを特定し、UIでの実装に推奨するモデルを決定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70247088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 離職予測の最適モデル\n",
    "best_attrition_model = max(model_results.items(), key=lambda x: x[1]['roc_auc'])[0]\n",
    "best_attrition_auc = model_results[best_attrition_model]['roc_auc']\n",
    "best_attrition_acc = model_results[best_attrition_model]['accuracy']\n",
    "\n",
    "# 給与予測の最適モデル\n",
    "best_salary_model = max(regression_results.items(), key=lambda x: x[1]['r2'])[0]\n",
    "best_salary_r2 = regression_results[best_salary_model]['r2']\n",
    "best_salary_mae = regression_results[best_salary_model]['mae']\n",
    "\n",
    "print(\"===== モデル評価結果まとめ =====\\n\")\n",
    "print(\"【離職予測】\")\n",
    "print(f\"最適モデル: {best_attrition_model}\")\n",
    "print(f\"ROC-AUC: {best_attrition_auc:.4f}\")\n",
    "print(f\"精度: {best_attrition_acc:.4f}\\n\")\n",
    "\n",
    "print(\"【給与予測】\")\n",
    "print(f\"最適モデル: {best_salary_model}\")\n",
    "print(f\"R²スコア: {best_salary_r2:.4f}\")\n",
    "print(f\"平均絶対誤差: {best_salary_mae:.2f}\\n\")\n",
    "\n",
    "print(\"===== UIでの実装推奨 =====\\n\")\n",
    "print(\"離職予測UI: RandomForest、XGBoost、LightGBMの3モデルを選択可能に実装\\n\")\n",
    "print(\"給与予測UI: RandomForest、XGBoost、LightGBM、線形回帰、勾配ブースティングの5モデルを選択可能に実装\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8ae2a3",
   "metadata": {},
   "source": [
    "## まとめ\n",
    "\n",
    "この分析では、離職予測と給与予測のための複数の機械学習モデルを比較しました。\n",
    "\n",
    "**離職予測については**：\n",
    "- XGBoostモデルが最も高いROC-AUCスコアを達成\n",
    "- RandomForestとLightGBMも競争力のある性能を示した\n",
    "- 業務特性（OverTime）、職務満足度、勤続年数などが重要な予測因子として特定された\n",
    "\n",
    "**給与予測については**：\n",
    "- 勾配ブースティング系の手法が高い精度を示した\n",
    "- 役職レベル、勤続年数、総労働経験年数が給与を予測する上で最も重要な要因\n",
    "\n",
    "**実装推奨**：\n",
    "ユーザーが複数のモデルから選択できるUIを実装することで、各モデルの特性や予測結果の違いを比較分析できるようにします。XGBoostとLightGBMを追加することで、より高度な分析が可能になります。"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
