import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from src.data.loader import load_hr_data
# ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–å¯¾å¿œã¨ PDF å‡ºåŠ›ç”¨ã®ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from src.utils.layout_utils import (
    display_optimized_chart,
    create_responsive_columns,
    add_page_break,
    format_dataframe_for_display
)

def show():
    """
    äººæç²å¾—åˆ†æãƒšãƒ¼ã‚¸ã‚’è¡¨ç¤ºã™ã‚‹é–¢æ•°
    """
    st.title("äººæç²å¾—åˆ†æ")
    st.write("æ¡ç”¨ãƒ—ãƒ­ã‚»ã‚¹ã®åˆ†æã¨åŠ¹ç‡åŒ–ææ¡ˆ")
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰
    df = load_hr_data()
    
    # ãƒ€ãƒŸãƒ¼ã®æ¡ç”¨ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆï¼ˆå®Ÿéš›ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã¯å®Ÿãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ï¼‰
    # å®Ÿãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã€æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ä»®æƒ³çš„ãªæ¡ç”¨ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
    
    # éå»10ãƒ¶æœˆåˆ†ã®æ¡ç”¨ãƒ‡ãƒ¼ã‚¿ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    np.random.seed(42)  # å†ç¾æ€§ã®ãŸã‚
    
    months = ["2024-07", "2024-08", "2024-09", "2024-10", "2024-11", "2024-12", 
              "2025-01", "2025-02", "2025-03", "2025-04"]
    
    recruitment_data = []
    
    departments = df['Department'].unique()
    jobroles = df['JobRole'].unique()
    
    for month in months:
        # å„éƒ¨é–€ãƒ»è·ç¨®ã”ã¨ã®æ¡ç”¨æ´»å‹•ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        for dept in departments:
            for role in jobroles:
                # æ¯é›†å›£ã®ä¸­ã§ã€ã“ã®éƒ¨é–€ãƒ»è·ç¨®ã®çµ„ã¿åˆã‚ã›ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
                if len(df[(df['Department'] == dept) & (df['JobRole'] == role)]) > 0:
                    # å¿œå‹Ÿè€…æ•°ï¼ˆãƒ©ãƒ³ãƒ€ãƒ ï¼‰
                    applicants = np.random.randint(2, 30)
                    
                    # ä¸€æ¬¡é¢æ¥é€šéè€…
                    first_interview = np.random.randint(1, max(2, int(applicants * 0.7)))
                    
                    # äºŒæ¬¡é¢æ¥é€šéè€…
                    second_interview = np.random.randint(1, max(2, int(first_interview * 0.7)))
                    
                    # ã‚ªãƒ•ã‚¡ãƒ¼æ•°
                    offers = np.random.randint(0, max(1, int(second_interview * 0.8)))
                    
                    # å†…å®šæ‰¿è«¾æ•°
                    acceptances = np.random.randint(0, max(1, offers))
                    
                    # æ¡ç”¨ã‚³ã‚¹ãƒˆï¼ˆå¿œå‹Ÿè€…æ•°ã¨å½¹è·ãƒ¬ãƒ™ãƒ«ã«åŸºã¥ãï¼‰
                    avg_level = df[(df['Department'] == dept) & (df['JobRole'] == role)]['JobLevel'].mean()
                    cost_per_hire = int(200000 + avg_level * 50000 + applicants * 2000)
                    
                    # ãƒ‡ãƒ¼ã‚¿è¿½åŠ 
                    recruitment_data.append({
                        'Month': month,
                        'Department': dept,
                        'JobRole': role,
                        'Applicants': applicants,
                        'FirstInterview': first_interview,
                        'SecondInterview': second_interview,
                        'Offers': offers,
                        'Acceptances': acceptances,
                        'CostPerHire': cost_per_hire,
                        'TimeToFill': np.random.randint(20, 90),  # æ¡ç”¨ã«ã‹ã‹ã£ãŸæ—¥æ•°
                        'SourceChannel': np.random.choice(['ãƒªãƒ•ã‚¡ãƒ©ãƒ«', 'æ±‚äººã‚µã‚¤ãƒˆ', 'SNS', 'è»¢è·ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ', 'è‡ªç¤¾ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆ'], 
                                                       p=[0.2, 0.3, 0.15, 0.25, 0.1])
                    })
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ åŒ–
    recruitment_df = pd.DataFrame(recruitment_data)
    
    # åˆ†æç”¨ã‚¿ãƒ–ã®ä½œæˆ
    tab1, tab2, tab3 = st.tabs(["ğŸ“Š æ¡ç”¨ãƒ•ã‚¡ãƒãƒ«åˆ†æ", "ğŸ’° æ¡ç”¨ã‚³ã‚¹ãƒˆåˆ†æ", "ğŸ” æ¡ç”¨ã‚½ãƒ¼ã‚¹åˆ†æ"])
    
    with tab1:
        st.header("æ¡ç”¨ãƒ•ã‚¡ãƒãƒ«åˆ†æ")
        
        # éƒ¨é–€ãƒ»è·ç¨®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
        col1, col2 = create_responsive_columns()
        
        with col1:
            dept_filter = st.multiselect(
                "éƒ¨é–€",
                options=recruitment_df['Department'].unique(),
                default=recruitment_df['Department'].unique()
            )
        
        with col2:
            role_filter = st.multiselect(
                "è·ç¨®",
                options=recruitment_df['JobRole'].unique(),
                default=recruitment_df['JobRole'].unique()
            )
        
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
        filtered_df = recruitment_df[
            (recruitment_df['Department'].isin(dept_filter)) &
            (recruitment_df['JobRole'].isin(role_filter))
        ]
        
        # æœŸé–“ã”ã¨ã®æ¡ç”¨ãƒ•ã‚¡ãƒãƒ«
        st.subheader("æœŸé–“ã”ã¨ã®æ¡ç”¨ãƒ•ã‚¡ãƒãƒ«")
        
        # æœŸé–“åˆ¥é›†è¨ˆ
        funnel_by_month = filtered_df.groupby('Month').agg({
            'Applicants': 'sum',
            'FirstInterview': 'sum',
            'SecondInterview': 'sum',
            'Offers': 'sum',
            'Acceptances': 'sum'
        }).reset_index()
        
        # è»¢æ›ç‡ã®è¨ˆç®—
        funnel_by_month['FirstInterviewRate'] = funnel_by_month['FirstInterview'] / funnel_by_month['Applicants']
        funnel_by_month['SecondInterviewRate'] = funnel_by_month['SecondInterview'] / funnel_by_month['FirstInterview']
        funnel_by_month['OfferRate'] = funnel_by_month['Offers'] / funnel_by_month['SecondInterview']
        funnel_by_month['AcceptanceRate'] = funnel_by_month['Acceptances'] / funnel_by_month['Offers']
        funnel_by_month['OverallConversionRate'] = funnel_by_month['Acceptances'] / funnel_by_month['Applicants']
        
        # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã§ã®å¯è¦–åŒ–
        conversion_metrics = ['FirstInterviewRate', 'SecondInterviewRate', 'OfferRate', 'AcceptanceRate', 'OverallConversionRate']
        conversion_labels = ['ä¸€æ¬¡é¢æ¥ç‡', 'äºŒæ¬¡é¢æ¥ç‡', 'ã‚ªãƒ•ã‚¡ãƒ¼ç‡', 'å†…å®šæ‰¿è«¾ç‡', 'å…¨ä½“è»¢æ›ç‡']
        
        # è»¢æ›ç‡è¡¨ç¤ºç”¨ã®ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
        heat_data = funnel_by_month[['Month'] + conversion_metrics].set_index('Month')
        
        # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—è¡¨ç¤ºå‰ã«åˆ—åã‚’æ—¥æœ¬èªã«å¤‰æ›
        heat_data.columns = conversion_labels
        
        fig = px.imshow(
            heat_data.T, 
            text_auto='.1%',
            aspect="auto",
            color_continuous_scale='RdYlGn',
            title="æœˆåˆ¥æ¡ç”¨è»¢æ›ç‡ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—"
        )
        
        # æœ€é©åŒ–ã—ãŸå›³ã‚’è¡¨ç¤º
        display_optimized_chart(fig)
        
        # æ¡ç”¨ãƒ•ã‚¡ãƒãƒ«ã®å¯è¦–åŒ–
        st.subheader("å…¨æœŸé–“ã®æ¡ç”¨ãƒ•ã‚¡ãƒãƒ«")
        
        # å…¨æœŸé–“ã®é›†è¨ˆ
        total_funnel = filtered_df.sum()
        funnel_metrics = ['Applicants', 'FirstInterview', 'SecondInterview', 'Offers', 'Acceptances']
        funnel_values = total_funnel[funnel_metrics].values
        funnel_labels = ['å¿œå‹Ÿè€…', 'ä¸€æ¬¡é¢æ¥', 'äºŒæ¬¡é¢æ¥', 'ã‚ªãƒ•ã‚¡ãƒ¼', 'å†…å®šæ‰¿è«¾']
        
        # ãƒ•ã‚¡ãƒãƒ«ãƒãƒ£ãƒ¼ãƒˆ
        fig = go.Figure(go.Funnel(
            y=funnel_labels,
            x=funnel_values,
            textinfo="value+percent initial",
            marker=dict(color=["royalblue", "mediumslateblue", "slateblue", "darkslateblue", "midnightblue"])
        ))
        
        fig.update_layout(title_text="æ¡ç”¨ãƒ•ã‚¡ãƒãƒ«åˆ†æ")
        
        # æœ€é©åŒ–ã—ãŸå›³ã‚’è¡¨ç¤º
        display_optimized_chart(fig)
        
        # PDFå‡ºåŠ›æ™‚ã®ãƒšãƒ¼ã‚¸åŒºåˆ‡ã‚Š
        add_page_break()
        
        # éƒ¨é–€åˆ¥ã®æ¡ç”¨ãƒ•ã‚¡ãƒãƒ«åŠ¹ç‡
        st.subheader("éƒ¨é–€åˆ¥ã®æ¡ç”¨ãƒ•ã‚¡ãƒãƒ«åŠ¹ç‡")
        
        dept_funnel = filtered_df.groupby('Department').agg({
            'Applicants': 'sum',
            'FirstInterview': 'sum',
            'SecondInterview': 'sum',
            'Offers': 'sum',
            'Acceptances': 'sum'
        }).reset_index()
        
        dept_funnel['OverallConversionRate'] = dept_funnel['Acceptances'] / dept_funnel['Applicants']
        dept_funnel = dept_funnel.sort_values('OverallConversionRate', ascending=False)
        
        fig = px.bar(
            dept_funnel,
            x='Department',
            y='OverallConversionRate',
            title="éƒ¨é–€åˆ¥ã®å¿œå‹Ÿè€…â†’å†…å®šæ‰¿è«¾ã®è»¢æ›ç‡",
            color='OverallConversionRate',
            color_continuous_scale='Viridis',
            text_auto='.1%'
        )
        
        # æœ€é©åŒ–ã—ãŸå›³ã‚’è¡¨ç¤º
        display_optimized_chart(fig)
        
        # è·ç¨®åˆ¥ã®æ¡ç”¨é›£æ˜“åº¦åˆ†æ
        st.subheader("è·ç¨®åˆ¥ã®æ¡ç”¨é›£æ˜“åº¦")
        
        role_difficulty = filtered_df.groupby('JobRole').agg({
            'Applicants': 'sum',
            'Acceptances': 'sum',
            'TimeToFill': 'mean'
        }).reset_index()
        
        role_difficulty['ApplicantsPerHire'] = role_difficulty['Applicants'] / role_difficulty['Acceptances']
        role_difficulty = role_difficulty.sort_values('ApplicantsPerHire', ascending=False)
        
        fig = px.scatter(
            role_difficulty,
            x='ApplicantsPerHire',
            y='TimeToFill',
            color='Acceptances',
            size='Applicants',
            hover_name='JobRole',
            title="è·ç¨®åˆ¥ã®æ¡ç”¨é›£æ˜“åº¦ãƒãƒƒãƒ—",
            labels={
                'ApplicantsPerHire': '1æ¡ç”¨ã‚ãŸã‚Šã®å¿œå‹Ÿè€…æ•°',
                'TimeToFill': 'å¹³å‡æ¡ç”¨æ‰€è¦æ—¥æ•°',
                'Acceptances': 'æ¡ç”¨æ•°'
            }
        )
        
        # æœ€é©åŒ–ã—ãŸå›³ã‚’è¡¨ç¤º
        display_optimized_chart(fig)
        
        # æ¡ç”¨ãƒ—ãƒ­ã‚»ã‚¹ãƒœãƒˆãƒ«ãƒãƒƒã‚¯åˆ†æ
        st.subheader("æ¡ç”¨ãƒ—ãƒ­ã‚»ã‚¹ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯åˆ†æ")
        
        # å…¨æœŸé–“ã®è»¢æ›ç‡å¹³å‡
        avg_conversion = {
            'å¿œå‹Ÿâ†’ä¸€æ¬¡é¢æ¥': (filtered_df['FirstInterview'].sum() / filtered_df['Applicants'].sum()),
            'ä¸€æ¬¡â†’äºŒæ¬¡é¢æ¥': (filtered_df['SecondInterview'].sum() / filtered_df['FirstInterview'].sum()),
            'äºŒæ¬¡é¢æ¥â†’ã‚ªãƒ•ã‚¡ãƒ¼': (filtered_df['Offers'].sum() / filtered_df['SecondInterview'].sum()),
            'ã‚ªãƒ•ã‚¡ãƒ¼â†’å†…å®šæ‰¿è«¾': (filtered_df['Acceptances'].sum() / filtered_df['Offers'].sum())
        }
        
        bottleneck_df = pd.DataFrame({
            'Stage': list(avg_conversion.keys()),
            'ConversionRate': list(avg_conversion.values())
        })
        
        bottleneck_df = bottleneck_df.sort_values('ConversionRate')
        
        fig = px.bar(
            bottleneck_df,
            x='Stage',
            y='ConversionRate',
            title="æ¡ç”¨ãƒ—ãƒ­ã‚»ã‚¹ã®æ®µéšåˆ¥è»¢æ›ç‡",
            color='ConversionRate',
            color_continuous_scale='RdYlGn',
            text_auto='.1%'
        )
        
        # ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã®è­˜åˆ¥
        bottleneck_stage = bottleneck_df.iloc[0]['Stage']
        bottleneck_rate = bottleneck_df.iloc[0]['ConversionRate']
        
        # æœ€é©åŒ–ã—ãŸå›³ã‚’è¡¨ç¤º
        display_optimized_chart(fig)
        
        st.info(f"**ä¸»è¦ãªãƒœãƒˆãƒ«ãƒãƒƒã‚¯**: {bottleneck_stage} (è»¢æ›ç‡: {bottleneck_rate:.1%})")
        
        # ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã«åŸºã¥ãæ”¹å–„ææ¡ˆ
        improvement_suggestions = {
            'å¿œå‹Ÿâ†’ä¸€æ¬¡é¢æ¥': [
                "æ¡ç”¨è¦ä»¶ã®æ˜ç¢ºåŒ–ã¨æ±‚äººæƒ…å ±ã®æ”¹å–„",
                "å¿œå‹Ÿè€…ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ãƒ—ãƒ­ã‚»ã‚¹ã®è¦‹ç›´ã—",
                "é©åˆ‡ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ»ã‚¹ã‚­ãƒ«æ¤œç´¢ã®å®Ÿæ–½"
            ],
            'ä¸€æ¬¡â†’äºŒæ¬¡é¢æ¥': [
                "é¢æ¥å®˜ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å¼·åŒ–",
                "ä¸€æ¬¡é¢æ¥ã®è©•ä¾¡åŸºæº–ã®è¦‹ç›´ã—",
                "å€™è£œè€…ã¸ã®ä¼šç¤¾æ–‡åŒ–ã¨ãƒ“ã‚¸ãƒ§ãƒ³ã®åŠ¹æœçš„ãªä¼é”"
            ],
            'äºŒæ¬¡é¢æ¥â†’ã‚ªãƒ•ã‚¡ãƒ¼': [
                "æœ€çµ‚é¢æ¥ã¨è©•ä¾¡ãƒ—ãƒ­ã‚»ã‚¹ã®åŠ¹ç‡åŒ–",
                "å†…éƒ¨æ‰¿èªãƒ—ãƒ­ã‚»ã‚¹ã®è¿…é€ŸåŒ–",
                "éƒ¨é–€ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã¨æ¡ç”¨æ‹…å½“ã®é€£æºå¼·åŒ–"
            ],
            'ã‚ªãƒ•ã‚¡ãƒ¼â†’å†…å®šæ‰¿è«¾': [
                "ã‚ªãƒ•ã‚¡ãƒ¼ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ç«¶äº‰åŠ›å¼·åŒ–",
                "å€™è£œè€…ã¨ã®ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³é »åº¦ã®å‘ä¸Š",
                "å…¥ç¤¾å‰ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®å°å…¥"
            ]
        }
        
        st.write("**æ”¹å–„ææ¡ˆ:**")
        for suggestion in improvement_suggestions[bottleneck_stage]:
            st.write(f"- {suggestion}")
    
    with tab2:
        st.header("æ¡ç”¨ã‚³ã‚¹ãƒˆåˆ†æ")
        
        # PDFå‡ºåŠ›æ™‚ã®ãƒšãƒ¼ã‚¸åŒºåˆ‡ã‚Š
        add_page_break()
        
        # å…¨ä½“ã®æ¡ç”¨ã‚³ã‚¹ãƒˆæ¦‚è¦
        total_cost = filtered_df['CostPerHire'].sum()
        total_hires = filtered_df['Acceptances'].sum()
        avg_cost_per_hire = total_cost / total_hires if total_hires > 0 else 0
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–å¯¾å¿œã®ãƒ¡ãƒˆãƒªãƒƒã‚¯è¡¨ç¤º
        col1, col2, col3 = create_responsive_columns([1, 1, 1])
        
        with col1:
            st.metric("ç·æ¡ç”¨ã‚³ã‚¹ãƒˆ", f"Â¥{total_cost:,.0f}")
        
        with col2:
            st.metric("ç·æ¡ç”¨æ•°", f"{total_hires:.0f}äºº")
        
        with col3:
            st.metric("å¹³å‡æ¡ç”¨å˜ä¾¡", f"Â¥{avg_cost_per_hire:,.0f}")
        
        # æœˆåˆ¥ã®æ¡ç”¨ã‚³ã‚¹ãƒˆã¨æ¡ç”¨æ•°ã®æ¨ç§»
        st.subheader("æœˆåˆ¥ã®æ¡ç”¨ã‚³ã‚¹ãƒˆã¨æ¡ç”¨æ•°ã®æ¨ç§»")
        
        monthly_cost = filtered_df.groupby('Month').agg({
            'CostPerHire': 'sum',
            'Acceptances': 'sum'
        }).reset_index()
        
        # æ¡ç”¨ã‚³ã‚¹ãƒˆã¨æ¡ç”¨æ•°ã®æ¨ç§»ã‚°ãƒ©ãƒ•
        fig = px.bar(
            monthly_cost,
            x='Month',
            y='CostPerHire',
            title="æœˆåˆ¥ã®æ¡ç”¨ã‚³ã‚¹ãƒˆã¨æ¡ç”¨æ•°",
            labels={'CostPerHire': 'æ¡ç”¨ã‚³ã‚¹ãƒˆ (å††)', 'Month': 'æœˆ'}
        )
        
        # æ¡ç”¨æ•°ã®ç·šã‚°ãƒ©ãƒ•ã‚’è¿½åŠ 
        fig.add_trace(
            go.Scatter(
                x=monthly_cost['Month'],
                y=monthly_cost['Acceptances'],
                mode='lines+markers',
                name='æ¡ç”¨æ•°',
                yaxis='y2'
            )
        )
        
        # 2è»¸ã‚°ãƒ©ãƒ•ã®è¨­å®š
        fig.update_layout(
            yaxis=dict(
                title='æ¡ç”¨ã‚³ã‚¹ãƒˆ (å††)',
                tickformat=",",  # æ¡åŒºåˆ‡ã‚Šã®ã‚«ãƒ³ãƒè¡¨ç¤ºã‚’è¿½åŠ 
                exponentformat='none'  # æŒ‡æ•°è¡¨è¨˜ã‚’ä½¿ç”¨ã—ãªã„
            ),
            yaxis2=dict(
                title='æ¡ç”¨æ•°',
                overlaying='y',
                side='right'
            ),
            legend=dict(
                orientation="h",
                yanchor="bottom",
                y=1.02,
                xanchor="right",
                x=1
            )
        )
        
        # ãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¤ºã®ä¿®æ­£
        for i in range(len(fig.data)):
            if hasattr(fig.data[i], 'type') and fig.data[i].type == 'bar':
                fig.data[i].text = ["Â¥{:,.0f}".format(val) for val in monthly_cost['CostPerHire']]
                fig.data[i].textposition = 'outside'
        
        # æœ€é©åŒ–ã—ãŸå›³ã‚’è¡¨ç¤º
        display_optimized_chart(fig)
        
        # éƒ¨é–€åˆ¥ã®æ¡ç”¨ã‚³ã‚¹ãƒˆåŠ¹ç‡
        st.subheader("éƒ¨é–€åˆ¥ã®æ¡ç”¨ã‚³ã‚¹ãƒˆåŠ¹ç‡")
        
        dept_cost = filtered_df.groupby('Department').agg({
            'CostPerHire': 'sum',
            'Acceptances': 'sum'
        }).reset_index()
        
        dept_cost['CostPerAcceptance'] = dept_cost['CostPerHire'] / dept_cost['Acceptances']
        dept_cost = dept_cost.sort_values('CostPerAcceptance')
        
        fig = px.bar(
            dept_cost,
            x='Department',
            y='CostPerAcceptance',
            title="éƒ¨é–€åˆ¥ã®æ¡ç”¨å˜ä¾¡",
            color='CostPerAcceptance',
            color_continuous_scale='Reds_r'
        )
        
        # yè»¸ã®ç¯„å›²ã¨æ›¸å¼ã‚’è¨­å®š
        fig.update_layout(
            yaxis=dict(
                tickformat=",",  # æ¡åŒºåˆ‡ã‚Šã®ã‚«ãƒ³ãƒè¡¨ç¤º
                exponentformat='none',  # æŒ‡æ•°è¡¨è¨˜ã‚’ä½¿ç”¨ã—ãªã„
                title="æ¡ç”¨å˜ä¾¡ (å††)"  # yè»¸ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’è¿½åŠ 
            )
        )
        
        # ãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¤ºã®ä¿®æ­£
        fig.update_traces(
            text=["Â¥{:,.0f}".format(val) for val in dept_cost['CostPerAcceptance']],
            textposition='outside'
        )
        
        # æœ€é©åŒ–ã—ãŸå›³ã‚’è¡¨ç¤º
        display_optimized_chart(fig)
        
        # PDFå‡ºåŠ›æ™‚ã®ãƒšãƒ¼ã‚¸åŒºåˆ‡ã‚Š
        add_page_break()
        
        # è·ç¨®åˆ¥ã®æ¡ç”¨ã‚³ã‚¹ãƒˆåŠ¹ç‡
        st.subheader("è·ç¨®åˆ¥ã®æ¡ç”¨ã‚³ã‚¹ãƒˆåŠ¹ç‡")
        
        role_cost = filtered_df.groupby('JobRole').agg({
            'CostPerHire': 'sum',
            'Acceptances': 'sum'
        }).reset_index()
        
        role_cost['CostPerAcceptance'] = role_cost['CostPerHire'] / role_cost['Acceptances']
        role_cost = role_cost.sort_values('CostPerAcceptance')
        
        fig = px.bar(
            role_cost,
            x='JobRole',
            y='CostPerAcceptance',
            title="è·ç¨®åˆ¥ã®æ¡ç”¨å˜ä¾¡",
            color='CostPerAcceptance',
            color_continuous_scale='Reds_r'
        )
        
        # yè»¸ã®ç¯„å›²ã¨æ›¸å¼ã‚’è¨­å®š
        fig.update_layout(
            xaxis_tickangle=-45,
            yaxis=dict(
                range=[0, 20000000],  # yè»¸ã®ç¯„å›²ã‚’0ã€œ20Mã«è¨­å®š
                tickformat=",",  # æ¡åŒºåˆ‡ã‚Šã®ã‚«ãƒ³ãƒè¡¨ç¤º
                title="æ¡ç”¨å˜ä¾¡ (å††)"  # yè»¸ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’è¿½åŠ 
            )
        )
        
        # ãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¤ºã®ä¿®æ­£
        fig.update_traces(
            text=["Â¥{:,.0f}".format(val) for val in role_cost['CostPerAcceptance']],
            textposition='outside'
        )
        
        # æœ€é©åŒ–ã—ãŸå›³ã‚’è¡¨ç¤º
        display_optimized_chart(fig)
        
        # æ¡ç”¨ã‚³ã‚¹ãƒˆæœ€é©åŒ–ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        st.subheader("æ¡ç”¨ã‚³ã‚¹ãƒˆæœ€é©åŒ–ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
        
        # æœ€é©åŒ–ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®é¸æŠ
        optimization_target = st.selectbox(
            "ã‚³ã‚¹ãƒˆæœ€é©åŒ–ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ",
            options=["é«˜ã‚³ã‚¹ãƒˆè·ç¨®ã®æœ€é©åŒ–", "æ¡ç”¨ãƒãƒ£ãƒãƒ«ã®é…åˆ†æœ€é©åŒ–", "æ¡ç”¨ãƒ—ãƒ­ã‚»ã‚¹ã®åŠ¹ç‡åŒ–"],
            index=0
        )
        
        if optimization_target == "é«˜ã‚³ã‚¹ãƒˆè·ç¨®ã®æœ€é©åŒ–":
            # é«˜ã‚³ã‚¹ãƒˆã®è·ç¨®ã‚’ç‰¹å®š
            high_cost_roles = role_cost.nlargest(3, 'CostPerAcceptance')
            
            st.write("**é«˜ã‚³ã‚¹ãƒˆè·ç¨®:**")
            for i, row in high_cost_roles.iterrows():
                st.write(f"- {row['JobRole']}: Â¥{row['CostPerAcceptance']:,.0f} / æ¡ç”¨")
            
            # æœ€é©åŒ–ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
            st.write("**ã‚³ã‚¹ãƒˆå‰Šæ¸›ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³**")
            
            cost_reduction = st.slider(
                "é«˜ã‚³ã‚¹ãƒˆè·ç¨®ã®ã‚³ã‚¹ãƒˆå‰Šæ¸›ç›®æ¨™ (%)",
                min_value=5,
                max_value=30,
                value=15,
                step=5
            )
            
            # ã‚³ã‚¹ãƒˆå‰Šæ¸›åŠ¹æœã®è¨ˆç®—
            high_cost_total = high_cost_roles['CostPerHire'].sum()
            savings = high_cost_total * (cost_reduction / 100)
            
            st.success(f"é«˜ã‚³ã‚¹ãƒˆè·ç¨®ã®ã‚³ã‚¹ãƒˆæœ€é©åŒ–ã«ã‚ˆã‚Šã€ç´„ Â¥{savings:,.0f} ã®å‰Šæ¸›ãŒè¦‹è¾¼ã¾ã‚Œã¾ã™ï¼ˆ{cost_reduction}%å‰Šæ¸›ã®å ´åˆï¼‰")
            
            # ã‚³ã‚¹ãƒˆå‰Šæ¸›ã®å…·ä½“çš„ãªæ–¹æ³•
            st.write("**ã‚³ã‚¹ãƒˆå‰Šæ¸›ã®ãŸã‚ã®æ”¹å–„ç­–:**")
            
            cost_savings_methods = [
                "ãƒªãƒ•ã‚¡ãƒ©ãƒ«æ¡ç”¨ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®å¼·åŒ–ï¼ˆå¾“æ¥­å“¡ç´¹ä»‹ã®å ±é…¬ã‚’æœ€é©åŒ–ï¼‰",
                "æ¡ç”¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè²»ç”¨ã®äº¤æ¸‰ã¨è¤‡æ•°ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æ¯”è¼ƒè©•ä¾¡",
                "å†…éƒ¨æ¡ç”¨æ‹…å½“è€…ã®ã‚¹ã‚­ãƒ«å‘ä¸Šã¨ãƒ„ãƒ¼ãƒ«å°å…¥ã«ã‚ˆã‚‹å¤–éƒ¨ä¾å­˜åº¦ã®å‰Šæ¸›",
                "æ¡ç”¨ãƒ–ãƒ©ãƒ³ãƒ‡ã‚£ãƒ³ã‚°å¼·åŒ–ã«ã‚ˆã‚‹ç›´æ¥å¿œå‹Ÿã®å¢—åŠ ",
                "æ¡ç”¨ãƒ—ãƒ­ã‚»ã‚¹ã®åŠ¹ç‡åŒ–ã«ã‚ˆã‚‹æ™‚é–“çŸ­ç¸®"
            ]
            
            for method in cost_savings_methods:
                st.write(f"- {method}")
        
        elif optimization_target == "æ¡ç”¨ãƒãƒ£ãƒãƒ«ã®é…åˆ†æœ€é©åŒ–":
            # ãƒãƒ£ãƒãƒ«åˆ¥ã®ã‚³ã‚¹ãƒˆåŠ¹ç‡
            channel_cost = filtered_df.groupby('SourceChannel').agg({
                'CostPerHire': 'sum',
                'Acceptances': 'sum'
            }).reset_index()
            
            channel_cost['CostPerAcceptance'] = channel_cost['CostPerHire'] / channel_cost['Acceptances']
            channel_cost = channel_cost.sort_values('CostPerAcceptance')
            
            # ç¾åœ¨ã®ãƒãƒ£ãƒãƒ«é…åˆ†
            current_allocation = filtered_df.groupby('SourceChannel').size() / len(filtered_df)
            
            # æœ€é©ãªé…åˆ†ã®ææ¡ˆï¼ˆã‚³ã‚¹ãƒˆåŠ¹ç‡ã«åŸºã¥ãï¼‰
            # å˜ç´”åŒ–ã®ãŸã‚ã€ã‚³ã‚¹ãƒˆåŠ¹ç‡ã®é€†æ•°ã«æ¯”ä¾‹ã—ãŸé…åˆ†ã‚’ææ¡ˆ
            efficiency = 1 / channel_cost['CostPerAcceptance']
            proposed_allocation = efficiency / efficiency.sum()
            
            # ãƒãƒ£ãƒãƒ«é…åˆ†æ¯”è¼ƒ
            allocation_df = pd.DataFrame({
                'SourceChannel': channel_cost['SourceChannel'],
                'ç¾åœ¨ã®é…åˆ†': [current_allocation.get(channel, 0) for channel in channel_cost['SourceChannel']],
                'æ¨å¥¨é…åˆ†': proposed_allocation.values,
                'ã‚³ã‚¹ãƒˆåŠ¹ç‡': channel_cost['CostPerAcceptance'].values
            })
            
            # å¯è¦–åŒ–
            fig = go.Figure()
            
            fig.add_trace(go.Bar(
                x=allocation_df['SourceChannel'],
                y=allocation_df['ç¾åœ¨ã®é…åˆ†'],
                name='ç¾åœ¨ã®é…åˆ†',
                marker_color='royalblue'
            ))
            
            fig.add_trace(go.Bar(
                x=allocation_df['SourceChannel'],
                y=allocation_df['æ¨å¥¨é…åˆ†'],
                name='æ¨å¥¨é…åˆ†',
                marker_color='green'
            ))
            
            fig.update_layout(
                title="æ¡ç”¨ãƒãƒ£ãƒãƒ«é…åˆ†ã®æœ€é©åŒ–",
                barmode='group',
                yaxis=dict(title='é…åˆ†ç‡'),
                xaxis=dict(title='æ¡ç”¨ãƒãƒ£ãƒãƒ«')
            )
            
            # æœ€é©åŒ–ã—ãŸå›³ã‚’è¡¨ç¤º
            display_optimized_chart(fig)
            
            # ã‚³ã‚¹ãƒˆå‰Šæ¸›åŠ¹æœã®è©¦ç®—
            current_cost = total_cost
            
            # æ¨å¥¨é…åˆ†ã‚’é©ç”¨ã—ãŸå ´åˆã®æƒ³å®šã‚³ã‚¹ãƒˆã‚’è¨ˆç®—
            theoretical_cost = 0
            for i, row in allocation_df.iterrows():
                channel_hire_need = total_hires * row['æ¨å¥¨é…åˆ†']
                theoretical_cost += channel_hire_need * row['ã‚³ã‚¹ãƒˆåŠ¹ç‡']
            
            cost_diff = current_cost - theoretical_cost
            cost_diff_pct = (cost_diff / current_cost) * 100
            
            st.success(f"ãƒãƒ£ãƒãƒ«é…åˆ†ã®æœ€é©åŒ–ã«ã‚ˆã‚Šã€ç´„ Â¥{cost_diff:,.0f} ({cost_diff_pct:.1f}%) ã®ã‚³ã‚¹ãƒˆå‰Šæ¸›ãŒè¦‹è¾¼ã¾ã‚Œã¾ã™")
            
        elif optimization_target == "æ¡ç”¨ãƒ—ãƒ­ã‚»ã‚¹ã®åŠ¹ç‡åŒ–":
            # æ¡ç”¨ãƒ—ãƒ­ã‚»ã‚¹ã®å„æ®µéšã®åŠ¹ç‡ã‚’åˆ†æ
            process_time = {
                'å¿œå‹Ÿè€…ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°': 2,  # æ—¥æ•°ï¼ˆä»®å®šï¼‰
                'ä¸€æ¬¡é¢æ¥èª¿æ•´': 3,
                'ä¸€æ¬¡é¢æ¥å®Ÿæ–½': 1,
                'äºŒæ¬¡é¢æ¥èª¿æ•´': 4,
                'äºŒæ¬¡é¢æ¥å®Ÿæ–½': 1,
                'å†…éƒ¨è©•ä¾¡ãƒ»æ‰¿èª': 5,
                'ã‚ªãƒ•ã‚¡ãƒ¼æº–å‚™': 2,
                'ã‚ªãƒ•ã‚¡ãƒ¼äº¤æ¸‰': 3
            }
            
            process_df = pd.DataFrame({
                'Process': list(process_time.keys()),
                'Days': list(process_time.values())
            })
            
            # ç¾åœ¨ã®ç·æ—¥æ•°
            current_days = sum(process_time.values())
            
            # å¯è¦–åŒ–
            fig = px.bar(
                process_df,
                x='Process',
                y='Days',
                title="æ¡ç”¨ãƒ—ãƒ­ã‚»ã‚¹ã®æ‰€è¦æ—¥æ•°",
                color='Days',
                color_continuous_scale='Blues',
                text_auto='.0f'
            )
            
            # æœ€é©åŒ–ã—ãŸå›³ã‚’è¡¨ç¤º
            display_optimized_chart(fig)
            
            # åŠ¹ç‡åŒ–ç›®æ¨™
            process_improvement = st.slider(
                "ãƒ—ãƒ­ã‚»ã‚¹åŠ¹ç‡åŒ–ã«ã‚ˆã‚‹æ—¥æ•°å‰Šæ¸›ç›®æ¨™ (%)",
                min_value=10,
                max_value=40,
                value=20,
                step=5
            )
            
            # åŠ¹ç‡åŒ–å¾Œã®æ—¥æ•°
            improved_days = current_days * (1 - process_improvement / 100)
            days_saved = current_days - improved_days
            
            st.success(f"ãƒ—ãƒ­ã‚»ã‚¹åŠ¹ç‡åŒ–ã«ã‚ˆã‚Šã€æ¡ç”¨æ‰€è¦æ—¥æ•°ãŒ {current_days:.0f}æ—¥ ã‹ã‚‰ {improved_days:.0f}æ—¥ ã«çŸ­ç¸®å¯èƒ½ã§ã™ï¼ˆ{days_saved:.0f}æ—¥ã®çŸ­ç¸®ï¼‰")
            
            # åŠ¹ç‡åŒ–ã«ã‚ˆã‚‹å‰¯æ¬¡çš„åŠ¹æœ
            st.write("**åŠ¹ç‡åŒ–ã«ã‚ˆã‚‹å‰¯æ¬¡çš„åŠ¹æœ:**")
            
            secondary_benefits = [
                f"å€™è£œè€…ä½“é¨“ã®å‘ä¸Šã«ã‚ˆã‚‹å†…å®šæ‰¿è«¾ç‡ã®ä¸Šæ˜‡ï¼ˆæ¨å®š +{process_improvement/2:.0f}%ï¼‰",
                f"æ¡ç”¨æ‹…å½“è€…ã®å·¥æ•°å‰Šæ¸›ã«ã‚ˆã‚‹äººä»¶è²»ã®å‰Šæ¸›ï¼ˆæ¨å®š Â¥{process_improvement*10000:.0f}/æ¡ç”¨ï¼‰",
                f"æ¡ç”¨æœŸé–“çŸ­ç¸®ã«ã‚ˆã‚‹æ©Ÿä¼šæå¤±ã®å‰Šæ¸›ï¼ˆæ¨å®š Â¥{days_saved*20000:.0f}/æ¡ç”¨ï¼‰",
                "æ¡ç”¨ãƒ—ãƒ­ã‚»ã‚¹ã®æ¨™æº–åŒ–ã«ã‚ˆã‚‹å“è³ªå‘ä¸Š",
                "å„ªç§€ãªå€™è£œè€…ã®ç²å¾—ç¢ºç‡ã®å‘ä¸Š"
            ]
            
            for benefit in secondary_benefits:
                st.write(f"- {benefit}")
    
    with tab3:
        st.header("æ¡ç”¨ã‚½ãƒ¼ã‚¹åˆ†æ")
        
        # PDFå‡ºåŠ›æ™‚ã®ãƒšãƒ¼ã‚¸åŒºåˆ‡ã‚Š
        add_page_break()
        
        # æ¡ç”¨ã‚½ãƒ¼ã‚¹åˆ¥ã®åŠ¹ç‡æ€§
        st.subheader("æ¡ç”¨ã‚½ãƒ¼ã‚¹åˆ¥ã®åŠ¹ç‡æ€§")
        
        source_metrics = filtered_df.groupby('SourceChannel').agg({
            'Applicants': 'sum',
            'FirstInterview': 'sum',
            'Offers': 'sum',
            'Acceptances': 'sum',
            'CostPerHire': 'sum'
        }).reset_index()
        
        source_metrics['ApplicantToHire'] = source_metrics['Applicants'] / source_metrics['Acceptances']
        source_metrics['OfferAcceptanceRate'] = source_metrics['Acceptances'] / source_metrics['Offers']
        source_metrics['CostPerHire'] = source_metrics['CostPerHire'] / source_metrics['Acceptances']
        
        # ã‚½ãƒ¼ã‚¹åŠ¹ç‡ã®ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆ
        source_radar = source_metrics[['SourceChannel', 'ApplicantToHire', 'OfferAcceptanceRate', 'CostPerHire']]
        
        # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚’è¡Œã„ã€ã™ã¹ã¦ã®æŒ‡æ¨™ã§é«˜ã„ã»ã©è‰¯ããªã‚‹ã‚ˆã†ã«å¤‰æ›
        max_cost = source_radar['CostPerHire'].max()
        source_radar['CostEfficiency'] = max_cost / source_radar['CostPerHire']
        
        max_app_to_hire = source_radar['ApplicantToHire'].max()
        source_radar['ApplicationEfficiency'] = max_app_to_hire / source_radar['ApplicantToHire']
        
        # ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆç”¨ã®ãƒ‡ãƒ¼ã‚¿æº–å‚™
        fig = go.Figure()
        
        categories = ['å¿œå‹ŸåŠ¹ç‡', 'ã‚ªãƒ•ã‚¡ãƒ¼æ‰¿è«¾ç‡', 'ã‚³ã‚¹ãƒˆåŠ¹ç‡']
        
        for i, source in enumerate(source_radar['SourceChannel']):
            fig.add_trace(go.Scatterpolar(
                r=[
                    source_radar.iloc[i]['ApplicationEfficiency'],
                    source_radar.iloc[i]['OfferAcceptanceRate'],
                    source_radar.iloc[i]['CostEfficiency']
                ],
                theta=categories,
                fill='toself',
                name=source
            ))
        
        fig.update_layout(
            polar=dict(
                radialaxis=dict(
                    visible=True,
                    range=[0, 1]
                )
            ),
            title="æ¡ç”¨ã‚½ãƒ¼ã‚¹åŠ¹ç‡æ€§ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆ"
        )
        
        # æœ€é©åŒ–ã—ãŸå›³ã‚’è¡¨ç¤º
        display_optimized_chart(fig)
        
        # ã‚½ãƒ¼ã‚¹åˆ¥ã®ä¸»è¦æŒ‡æ¨™è¡¨
        st.subheader("æ¡ç”¨ã‚½ãƒ¼ã‚¹åˆ¥ã®ä¸»è¦æŒ‡æ¨™")
        
        source_display = source_metrics[['SourceChannel', 'Applicants', 'Acceptances', 'OfferAcceptanceRate', 'CostPerHire']]
        source_display = source_display.rename(columns={
            'SourceChannel': 'æ¡ç”¨ã‚½ãƒ¼ã‚¹',
            'Applicants': 'å¿œå‹Ÿè€…æ•°',
            'Acceptances': 'æ¡ç”¨æ•°',
            'OfferAcceptanceRate': 'ã‚ªãƒ•ã‚¡ãƒ¼æ‰¿è«¾ç‡',
            'CostPerHire': 'æ¡ç”¨å˜ä¾¡'
        })
        
        # è¡¨ç¤ºç”¨ã«æ›¸å¼ã‚’æ•´ãˆã‚‹
        source_display['ã‚ªãƒ•ã‚¡ãƒ¼æ‰¿è«¾ç‡'] = source_display['ã‚ªãƒ•ã‚¡ãƒ¼æ‰¿è«¾ç‡'].map('{:.1%}'.format)
        source_display['æ¡ç”¨å˜ä¾¡'] = source_display['æ¡ç”¨å˜ä¾¡'].map('Â¥{:,.0f}'.format)
        
        # æœ€é©åŒ–ã—ãŸãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ è¡¨ç¤º
        format_dataframe_for_display(source_display)
        
        # è·ç¨®åˆ¥ã®åŠ¹æœçš„ãªæ¡ç”¨ã‚½ãƒ¼ã‚¹
        st.subheader("è·ç¨®åˆ¥ã®åŠ¹æœçš„ãªæ¡ç”¨ã‚½ãƒ¼ã‚¹")
        
        # è·ç¨®ã¨ã‚½ãƒ¼ã‚¹ã®ã‚¯ãƒ­ã‚¹é›†è¨ˆ
        role_source = filtered_df.groupby(['JobRole', 'SourceChannel']).agg({
            'Acceptances': 'sum'
        }).reset_index()
        
        # è·ç¨®ã”ã¨ã®åˆè¨ˆæ¡ç”¨æ•°ã‚’è¨ˆç®—
        role_totals = role_source.groupby('JobRole')['Acceptances'].sum().reset_index()
        role_totals = role_totals.rename(columns={'Acceptances': 'TotalAcceptances'})
        
        # åˆè¨ˆã‚’çµåˆ
        role_source = pd.merge(role_source, role_totals, on='JobRole')
        
        # æ¯”ç‡ã‚’è¨ˆç®—
        role_source['Percentage'] = role_source['Acceptances'] / role_source['TotalAcceptances']
        
        # å„è·ç¨®ã§æœ€ã‚‚åŠ¹æœçš„ãªã‚½ãƒ¼ã‚¹ã‚’ç‰¹å®š
        best_sources = role_source.loc[role_source.groupby('JobRole')['Acceptances'].idxmax()]
        
        # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ç”¨ã®ãƒ”ãƒœãƒƒãƒˆãƒ†ãƒ¼ãƒ–ãƒ«
        pivot_role_source = role_source.pivot_table(
            index='JobRole',
            columns='SourceChannel',
            values='Percentage',
            aggfunc='sum'
        ).fillna(0)
        
        # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã®æç”»
        fig = px.imshow(
            pivot_role_source,
            text_auto='.0%',
            aspect="auto",
            color_continuous_scale='Blues',
            title="è·ç¨®åˆ¥ã®æ¡ç”¨ã‚½ãƒ¼ã‚¹åŠ¹æœãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—"
        )
        
        # æœ€é©åŒ–ã—ãŸå›³ã‚’è¡¨ç¤º
        display_optimized_chart(fig)
        
        # PDFå‡ºåŠ›æ™‚ã®ãƒšãƒ¼ã‚¸åŒºåˆ‡ã‚Š
        add_page_break()
        
        # ææ¡ˆï¼šè·ç¨®åˆ¥ã®æ¨å¥¨æ¡ç”¨ã‚½ãƒ¼ã‚¹
        st.subheader("è·ç¨®åˆ¥ã®æ¨å¥¨æ¡ç”¨æˆ¦ç•¥")
        
        selected_role = st.selectbox(
            "è·ç¨®ã‚’é¸æŠ",
            options=filtered_df['JobRole'].unique()
        )
        
        # é¸æŠã—ãŸè·ç¨®ã®ã‚½ãƒ¼ã‚¹åŠ¹æœ
        role_specific = role_source[role_source['JobRole'] == selected_role]
        role_specific = role_specific.sort_values('Acceptances', ascending=False)
        
        fig = px.pie(
            role_specific,
            names='SourceChannel',
            values='Acceptances',
            title=f"{selected_role}ã®æ¡ç”¨ã‚½ãƒ¼ã‚¹åˆ†å¸ƒ",
            hole=0.4
        )
        
        # æœ€é©åŒ–ã—ãŸå›³ã‚’è¡¨ç¤º
        display_optimized_chart(fig)
        
        # é¸æŠã—ãŸè·ç¨®ã«å¯¾ã™ã‚‹æ¨å¥¨æˆ¦ç•¥
        # å®Ÿéš›ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã¯ã€ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ãŸç²¾ç·»ãªæ¨å¥¨ãŒå¿…è¦
        recommendations = {
            'Sales Representative': {
                'best_sources': ['ãƒªãƒ•ã‚¡ãƒ©ãƒ«', 'SNS'],
                'strategies': [
                    "å–¶æ¥­ãƒãƒ¼ãƒ ã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’æ´»ç”¨ã—ãŸãƒªãƒ•ã‚¡ãƒ©ãƒ«æ¡ç”¨ã®å¼·åŒ–",
                    "LinkedInç­‰ã®ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«SNSã§ã®ã‚¿ãƒ¼ã‚²ãƒ†ã‚£ãƒ³ã‚°åºƒå‘Š",
                    "æ¥­ç•Œã‚¤ãƒ™ãƒ³ãƒˆã‚„ã‚»ãƒŸãƒŠãƒ¼ã§ã®æ¡ç”¨æ´»å‹•",
                    "æˆåŠŸå ±é…¬å‹ã®æ¡ç”¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æ´»ç”¨"
                ]
            },
            'Research Scientist': {
                'best_sources': ['è»¢è·ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ', 'è‡ªç¤¾ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆ'],
                'strategies': [
                    "å°‚é–€åˆ†é‡ã®å­¦ä¼šãƒ»ã‚«ãƒ³ãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ã§ã®ãƒªã‚¯ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°",
                    "å¤§å­¦ã‚„ç ”ç©¶æ©Ÿé–¢ã¨ã®é€£æº",
                    "ç§‘å­¦ç³»ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã§ã®ä¼æ¥­æŠ€è¡“ãƒ–ãƒ­ã‚°ç™ºä¿¡",
                    "ç ”ç©¶é–‹ç™ºç’°å¢ƒã®PRã‚’å¼·åŒ–ã—ãŸæ¡ç”¨ãƒšãƒ¼ã‚¸ã®ä½œæˆ"
                ]
            },
            'Human Resources': {
                'best_sources': ['æ±‚äººã‚µã‚¤ãƒˆ', 'ãƒªãƒ•ã‚¡ãƒ©ãƒ«'],
                'strategies': [
                    "HRå°‚é–€ã®è»¢è·ã‚µã‚¤ãƒˆã¸ã®æ±‚äººæ²è¼‰",
                    "HRç³»ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã¸ã®å‚åŠ ",
                    "HRèªå®šè³‡æ ¼ã‚’æŒã¤äººæã¸ã®ã‚¿ãƒ¼ã‚²ãƒ†ã‚£ãƒ³ã‚°",
                    "ç¤¾å†…ã‚¤ãƒ™ãƒ³ãƒˆæƒ…å ±ã®SNSç™ºä¿¡ã«ã‚ˆã‚‹ãƒ–ãƒ©ãƒ³ãƒ‡ã‚£ãƒ³ã‚°å¼·åŒ–"
                ]
            }
        }
        
        # ä»–ã®è·ç¨®ã«å¯¾ã™ã‚‹ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæ¨å¥¨
        default_recommendations = {
            'best_sources': ['æ±‚äººã‚µã‚¤ãƒˆ', 'ãƒªãƒ•ã‚¡ãƒ©ãƒ«'],
            'strategies': [
                "åŠ¹æœçš„ãªæ±‚äººå†…å®¹ã®æœ€é©åŒ–ï¼ˆè·å‹™å†…å®¹ã€å¿…è¦ã‚¹ã‚­ãƒ«ã€ä¼æ¥­æ–‡åŒ–ã®æ˜ç¢ºãªæç¤ºï¼‰",
                "å¾“æ¥­å“¡ãƒªãƒ•ã‚¡ãƒ©ãƒ«ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®å ±é…¬è¦‹ç›´ã—ã¨ä¿ƒé€²ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³",
                "æ¡ç”¨ãƒ–ãƒ©ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã®å¼·åŒ–ï¼ˆä¼æ¥­æ–‡åŒ–ã‚„æˆé•·æ©Ÿä¼šã®ã‚¢ãƒ”ãƒ¼ãƒ«ï¼‰",
                "ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå±¤ãŒåˆ©ç”¨ã™ã‚‹ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã¸ã®å‚åŠ "
            ]
        }
        
        role_rec = recommendations.get(selected_role, default_recommendations)
        
        st.write(f"**{selected_role}ã«åŠ¹æœçš„ãªæ¡ç”¨ã‚½ãƒ¼ã‚¹:** {', '.join(role_rec['best_sources'])}")
        
        st.write("**æ¨å¥¨æ¡ç”¨æˆ¦ç•¥:**")
        for strategy in role_rec['strategies']:
            st.write(f"- {strategy}")
        
        # æ¡ç”¨ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
        st.subheader("æ¡ç”¨ã‚½ãƒ¼ã‚¹ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ")
        
        source_trend = filtered_df.groupby(['Month', 'SourceChannel']).agg({
            'Acceptances': 'sum'
        }).reset_index()
        
        fig = px.line(
            source_trend,
            x='Month',
            y='Acceptances',
            color='SourceChannel',
            title="æœˆåˆ¥ã®æ¡ç”¨ã‚½ãƒ¼ã‚¹åŠ¹æœæ¨ç§»",
            markers=True
        )
        
        # æœ€é©åŒ–ã—ãŸå›³ã‚’è¡¨ç¤º
        display_optimized_chart(fig)
        
        # PDFå‡ºåŠ›æ™‚ã®ãƒšãƒ¼ã‚¸åŒºåˆ‡ã‚Š
        add_page_break()
        
        # åœ°åŸŸåˆ¥ãƒ»æ¡ç”¨ã‚½ãƒ¼ã‚¹åˆ†æï¼ˆãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ï¼‰
        st.subheader("åœ°åŸŸåˆ¥ã®åŠ¹æœçš„ãªæ¡ç”¨ã‚½ãƒ¼ã‚¹")
        
        # åœ°åŸŸæƒ…å ±ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«ç”Ÿæˆ
        np.random.seed(42)
        regions = ['æ±äº¬', 'å¤§é˜ª', 'åå¤å±‹', 'ç¦å²¡', 'æœ­å¹Œ', 'ä»™å°']
        region_data = []
        
        for _, row in filtered_df.iterrows():
            region = np.random.choice(regions)
            region_data.append({
                'Month': row['Month'],
                'Department': row['Department'],
                'JobRole': row['JobRole'],
                'SourceChannel': row['SourceChannel'],
                'Region': region,
                'Acceptances': row['Acceptances']
            })
        
        region_df = pd.DataFrame(region_data)
        
        # åœ°åŸŸåˆ¥ã®æ¡ç”¨ã‚½ãƒ¼ã‚¹åŠ¹æœ
        region_source = region_df.groupby(['Region', 'SourceChannel']).agg({
            'Acceptances': 'sum'
        }).reset_index()
        
        # åœ°åŸŸã”ã¨ã®åˆè¨ˆæ¡ç”¨æ•°ã‚’è¨ˆç®—
        region_totals = region_source.groupby('Region')['Acceptances'].sum().reset_index()
        region_totals = region_totals.rename(columns={'Acceptances': 'TotalAcceptances'})
        
        # åˆè¨ˆã‚’çµåˆ
        region_source = pd.merge(region_source, region_totals, on='Region')
        
        # æ¯”ç‡ã‚’è¨ˆç®—
        region_source['Percentage'] = region_source['Acceptances'] / region_source['TotalAcceptances']
        
        # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ç”¨ã®ãƒ”ãƒœãƒƒãƒˆãƒ†ãƒ¼ãƒ–ãƒ«
        pivot_region_source = region_source.pivot_table(
            index='Region',
            columns='SourceChannel',
            values='Percentage',
            aggfunc='sum'
        ).fillna(0)
        
        # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã®æç”»
        fig = px.imshow(
            pivot_region_source,
            text_auto='.0%',
            aspect="auto",
            color_continuous_scale='Blues',
            title="åœ°åŸŸåˆ¥ã®æ¡ç”¨ã‚½ãƒ¼ã‚¹åŠ¹æœãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—"
        )
        
        # æœ€é©åŒ–ã—ãŸå›³ã‚’è¡¨ç¤º
        display_optimized_chart(fig)
    
    # ãƒ•ãƒƒã‚¿ãƒ¼
    st.markdown("---")
    st.info("ã“ã®ãƒšãƒ¼ã‚¸ã§ã¯ã€æ¡ç”¨ãƒ—ãƒ­ã‚»ã‚¹ã®åŠ¹ç‡æ€§ã€ã‚³ã‚¹ãƒˆã€ãŠã‚ˆã³åŠ¹æœçš„ãªæ¡ç”¨ã‚½ãƒ¼ã‚¹ã«é–¢ã™ã‚‹åˆ†æã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚"
            "ã‚ˆã‚ŠåŠ¹æœçš„ãªæ¡ç”¨æˆ¦ç•¥ã®ç­–å®šã«ã”æ´»ç”¨ãã ã•ã„ã€‚")