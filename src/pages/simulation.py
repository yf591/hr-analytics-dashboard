import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from src.data.loader import load_hr_data
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingRegressor
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, r2_score, mean_absolute_error
import xgboost as xgb
import lightgbm as lgb
from src.models.attrition import MODELS

def show():
    """
    äºˆæ¸¬åˆ†æãƒ»ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒšãƒ¼ã‚¸ã‚’è¡¨ç¤ºã™ã‚‹é–¢æ•°
    """
    st.title("äºˆæ¸¬åˆ†æãƒ»ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
    st.write("æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹å°†æ¥äºˆæ¸¬ã¨äººäº‹æ–½ç­–ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰
    df = load_hr_data()
    
    # ã‚¿ãƒ–ã§åˆ†æå†…å®¹ã‚’æ•´ç†
    tab1, tab2, tab3 = st.tabs(["ğŸ”® é›¢è·äºˆæ¸¬", "ğŸ’° çµ¦ä¸äºˆæ¸¬", "ğŸ‘¥ äººå“¡è¨ˆç”»ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"])
    
    with tab1:
        st.header("é›¢è·äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«")
        
        # ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰ã¨è©•ä¾¡
        st.subheader("é›¢è·äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½")
        
        # äºˆæ¸¬ã«ä½¿ç”¨ã™ã‚‹ç‰¹å¾´é‡
        features = [
            'Age', 'MonthlyIncome', 'DistanceFromHome', 'OverTime',
            'JobSatisfaction', 'WorkLifeBalance', 'YearsAtCompany',
            'YearsSinceLastPromotion', 'JobLevel', 'MaritalStatus',
            'NumCompaniesWorked', 'TrainingTimesLastYear', 'BusinessTravel'
        ]
        
        # ç›®çš„å¤‰æ•° (Attrition)
        target = 'Attrition'
        
        # ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
        X = df[features].copy()
        y = df[target].copy()
        
        # ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã¨ã‚«ãƒ†ã‚´ãƒªã§ãªã„å¤‰æ•°ã®åˆ†é¡
        categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()
        numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()
        
        # ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ã®ãŸã‚ã®å‰å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
        categorical_transformer = OneHotEncoder(handle_unknown='ignore')
        numeric_transformer = StandardScaler()
        
        preprocessor = ColumnTransformer(
            transformers=[
                ('num', numeric_transformer, numeric_features),
                ('cat', categorical_transformer, categorical_features)
            ]
        )
        
        # ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
        attrition_pipe = Pipeline(steps=[
            ('preprocessor', preprocessor),
            ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))
        ])
        
        # ãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
        
        # ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’
        with st.spinner('ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ä¸­...'):
            attrition_pipe.fit(X_train, y_train)
        
        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã®äºˆæ¸¬
        y_pred = attrition_pipe.predict(X_test)
        
        # ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡
        accuracy = accuracy_score(y_test, y_pred)
        
        # çµæœè¡¨ç¤º
        col1, col2 = st.columns(2)
        
        with col1:
            st.metric("ãƒ¢ãƒ‡ãƒ«ç²¾åº¦", f"{accuracy:.2%}")
            
            # æ··åŒè¡Œåˆ—
            cm = confusion_matrix(y_test, y_pred)
            cm_df = pd.DataFrame(
                cm, 
                index=['å®Ÿéš›: åœ¨è·', 'å®Ÿéš›: é›¢è·'], 
                columns=['äºˆæ¸¬: åœ¨è·', 'äºˆæ¸¬: é›¢è·']
            )
            
            st.write("æ··åŒè¡Œåˆ—:")
            st.dataframe(cm_df)
        
        with col2:
            # ç‰¹å¾´é‡é‡è¦åº¦
            feature_names = (
                numeric_features + 
                list(attrition_pipe.named_steps['preprocessor'].transformers_[1][1].get_feature_names_out(categorical_features))
            )
            
            feature_importance = pd.DataFrame(
                attrition_pipe.named_steps['classifier'].feature_importances_,
                index=feature_names,
                columns=['importance']
            ).sort_values('importance', ascending=False)
            
            # ä¸Šä½10å€‹ã®ç‰¹å¾´é‡ã®ã¿è¡¨ç¤º
            top_features = feature_importance.head(10)
            
            fig = px.bar(
                top_features,
                y=top_features.index,
                x='importance',
                orientation='h',
                title="ç‰¹å¾´é‡é‡è¦åº¦ï¼ˆä¸Šä½10ï¼‰",
                labels={'importance': 'é‡è¦åº¦', 'index': 'ç‰¹å¾´é‡'}
            )
            
            st.plotly_chart(fig, use_container_width=True)
        
        # ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªé›¢è·äºˆæ¸¬
        st.subheader("ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªé›¢è·ãƒªã‚¹ã‚¯äºˆæ¸¬")
        st.write("å¾“æ¥­å“¡ã®ç‰¹æ€§ã‚’èª¿æ•´ã—ã¦ã€é›¢è·ãƒªã‚¹ã‚¯ã®å¤‰åŒ–ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ãã¾ã™ã€‚")
        
        col1, col2 = st.columns(2)
        
        with col1:
            age = st.slider("å¹´é½¢", min_value=18, max_value=60, value=35)
            job_level = st.selectbox("å½¹è·ãƒ¬ãƒ™ãƒ«", options=[1, 2, 3, 4, 5], index=1)
            monthly_income = st.slider("æœˆå", min_value=1000, max_value=20000, value=5000, step=500)
            distance = st.slider("é€šå‹¤è·é›¢(km)", min_value=1, max_value=30, value=10)
            job_satisfaction = st.selectbox("è·å‹™æº€è¶³åº¦", options=[1, 2, 3, 4], index=2)
            work_life_balance = st.selectbox("ãƒ¯ãƒ¼ã‚¯ãƒ©ã‚¤ãƒ•ãƒãƒ©ãƒ³ã‚¹", options=[1, 2, 3, 4], index=2)
        
        with col2:
            years_at_company = st.slider("å‹¤ç¶šå¹´æ•°", min_value=0, max_value=40, value=5)
            years_since_promotion = st.slider("å‰å›æ˜‡é€²ã‹ã‚‰ã®å¹´æ•°", min_value=0, max_value=15, value=2)
            num_companies = st.slider("éå»ã®å‹¤å‹™ä¼æ¥­æ•°", min_value=0, max_value=9, value=2)
            training_times = st.slider("æ˜¨å¹´ã®ç ”ä¿®å›æ•°", min_value=0, max_value=6, value=2)
            overtime = st.selectbox("æ®‹æ¥­", options=["Yes", "No"], index=0)
            marital_status = st.selectbox("å©šå§»çŠ¶æ³", options=["Single", "Married", "Divorced"], index=0)
            business_travel = st.selectbox("å‡ºå¼µé »åº¦", options=["Non-Travel", "Travel_Rarely", "Travel_Frequently"], index=1)
        
        # äºˆæ¸¬ç”¨ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ
        prediction_data = pd.DataFrame({
            'Age': [age],
            'JobLevel': [job_level],
            'MonthlyIncome': [monthly_income],
            'DistanceFromHome': [distance],
            'JobSatisfaction': [job_satisfaction],
            'WorkLifeBalance': [work_life_balance],
            'YearsAtCompany': [years_at_company],
            'YearsSinceLastPromotion': [years_since_promotion],
            'NumCompaniesWorked': [num_companies],
            'TrainingTimesLastYear': [training_times],
            'OverTime': [overtime],
            'MaritalStatus': [marital_status],
            'BusinessTravel': [business_travel]
        })
        
        # é›¢è·ç¢ºç‡ã®äºˆæ¸¬
        probability = attrition_pipe.predict_proba(prediction_data)[0, 1]
        risk_level = "é«˜" if probability > 0.7 else "ä¸­" if probability > 0.3 else "ä½"
        
        # çµæœã®è¡¨ç¤º
        st.subheader("é›¢è·ãƒªã‚¹ã‚¯äºˆæ¸¬çµæœ")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("é›¢è·ç¢ºç‡", f"{probability:.1%}")
        
        with col2:
            st.metric("ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«", risk_level)
        
        with col3:
            if risk_level == "é«˜":
                st.error("æ—©æ€¥ãªå¯¾å¿œãŒå¿…è¦ã§ã™")
            elif risk_level == "ä¸­":
                st.warning("æ³¨æ„ãŒå¿…è¦ã§ã™")
            else:
                st.success("ãƒªã‚¹ã‚¯ã¯ä½ã„ã§ã™")
        
        # ã€Œã‚‚ã—ï½ã ã£ãŸã‚‰ï¼Ÿã€ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        st.subheader("ã€Œã‚‚ã—ï½ã ã£ãŸã‚‰ï¼Ÿã€ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
        
        what_if_scenarios = st.multiselect(
            "ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã—ãŸã„å¤‰æ›´ã‚’é¸æŠã—ã¦ãã ã•ã„",
            options=[
                "çµ¦ä¸ã‚’20%ã‚¢ãƒƒãƒ—",
                "ç ”ä¿®å›æ•°ã‚’2å›å¢—ã‚„ã™",
                "æ®‹æ¥­ã‚’ãªãã™",
                "æ˜‡é€²ã•ã›ã‚‹",
                "ãƒ¯ãƒ¼ã‚¯ãƒ©ã‚¤ãƒ•ãƒãƒ©ãƒ³ã‚¹ã‚’æ”¹å–„"
            ]
        )
        
        if what_if_scenarios:
            # å…ƒã®ãƒ‡ãƒ¼ã‚¿ã‚’ã‚³ãƒ”ãƒ¼
            scenario_data = prediction_data.copy()
            
            for scenario in what_if_scenarios:
                if scenario == "çµ¦ä¸ã‚’20%ã‚¢ãƒƒãƒ—":
                    scenario_data['MonthlyIncome'] = scenario_data['MonthlyIncome'] * 1.2
                elif scenario == "ç ”ä¿®å›æ•°ã‚’2å›å¢—ã‚„ã™":
                    # .valuesã‚’ä½¿ã£ã¦å€¤ã‚’å–å¾—ã—ã€ã‚¹ã‚«ãƒ©ãƒ¼å€¤ã¨ã—ã¦å‡¦ç†ã™ã‚‹
                    curr_training = scenario_data['TrainingTimesLastYear'].values[0]
                    scenario_data['TrainingTimesLastYear'] = min(6, curr_training + 2)
                elif scenario == "æ®‹æ¥­ã‚’ãªãã™":
                    scenario_data['OverTime'] = "No"
                elif scenario == "æ˜‡é€²ã•ã›ã‚‹":
                    # .valuesã‚’ä½¿ã£ã¦å€¤ã‚’å–å¾—ã—ã€ã‚¹ã‚«ãƒ©ãƒ¼å€¤ã¨ã—ã¦å‡¦ç†ã™ã‚‹
                    curr_level = scenario_data['JobLevel'].values[0]
                    scenario_data['JobLevel'] = min(5, curr_level + 1)
                    scenario_data['YearsSinceLastPromotion'] = 0
                elif scenario == "ãƒ¯ãƒ¼ã‚¯ãƒ©ã‚¤ãƒ•ãƒãƒ©ãƒ³ã‚¹ã‚’æ”¹å–„":
                    # .valuesã‚’ä½¿ã£ã¦å€¤ã‚’å–å¾—ã—ã€ã‚¹ã‚«ãƒ©ãƒ¼å€¤ã¨ã—ã¦å‡¦ç†ã™ã‚‹
                    curr_wlb = scenario_data['WorkLifeBalance'].values[0]
                    scenario_data['WorkLifeBalance'] = min(4, curr_wlb + 1)
            
            # å¤‰æ›´å¾Œã®é›¢è·ç¢ºç‡äºˆæ¸¬
            new_probability = attrition_pipe.predict_proba(scenario_data)[0, 1]
            probability_change = new_probability - probability
            
            # çµæœè¡¨ç¤º
            st.write(f"é¸æŠã—ãŸå¤‰æ›´ã‚’é©ç”¨ã—ãŸå ´åˆã®é›¢è·ç¢ºç‡: **{new_probability:.1%}**")
            st.write(f"é›¢è·ç¢ºç‡ã®å¤‰åŒ–: **{probability_change:.1%}**")
            
            # ã‚²ãƒ¼ã‚¸ãƒãƒ£ãƒ¼ãƒˆã§ã®ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«æ¯”è¼ƒ
            fig = go.Figure(go.Indicator(
                mode="gauge+number+delta",
                value=new_probability * 100,
                delta={"reference": probability * 100, "valueformat": ".1f"},
                gauge={"axis": {"range": [0, 100]},
                      "bar": {"color": "darkblue"},
                      "steps": [
                          {"range": [0, 30], "color": "green"},
                          {"range": [30, 70], "color": "yellow"},
                          {"range": [70, 100], "color": "red"}
                      ],
                      "threshold": {
                          "line": {"color": "red", "width": 4},
                          "thickness": 0.75,
                          "value": 70
                      }},
                title={"text": "é›¢è·ç¢ºç‡ (%)"}
            ))
            
            st.plotly_chart(fig, use_container_width=True)
    
    with tab2:
        st.header("çµ¦ä¸äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«")
        
        # å›å¸°ãƒ¢ãƒ‡ãƒ«ã®è¾æ›¸ã‚’å®šç¾©
        REGRESSION_MODELS = {
            "ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆå›å¸°": RandomForestRegressor(n_estimators=100, random_state=42),
            "ç·šå½¢å›å¸°": LinearRegression(),
            "å‹¾é…ãƒ–ãƒ¼ã‚¹ãƒ†ã‚£ãƒ³ã‚°å›å¸°": GradientBoostingRegressor(n_estimators=100, random_state=42),
            "XGBoostå›å¸°": xgb.XGBRegressor(n_estimators=100, random_state=42),
            "LightGBMå›å¸°": lgb.LGBMRegressor(n_estimators=100, random_state=42)
        }
        
        # ãƒ¢ãƒ‡ãƒ«é¸æŠUI
        salary_model_type = st.selectbox(
            "çµ¦ä¸äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„",
            options=list(REGRESSION_MODELS.keys()),
            index=0,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆå›å¸°
            help="ç•°ãªã‚‹å›å¸°ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ç²¾åº¦ã‚’æ¯”è¼ƒã§ãã¾ã™"
        )
        
        # çµ¦ä¸äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰
        st.subheader("çµ¦ä¸äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½")
        
        # çµ¦ä¸äºˆæ¸¬ã«ä½¿ç”¨ã™ã‚‹ç‰¹å¾´é‡
        salary_features = [
            'JobLevel', 'Age', 'YearsAtCompany', 'TotalWorkingYears',
            'Department', 'JobRole', 'EducationField', 'Education',
            'PerformanceRating', 'Gender'
        ]
        
        # ç›®çš„å¤‰æ•°
        salary_target = 'MonthlyIncome'
        
        # æ¬ æå€¤ã®ãªã„ãƒ¬ã‚³ãƒ¼ãƒ‰ã ã‘ä½¿ç”¨
        salary_df = df[salary_features + [salary_target]].dropna()
        
        # ãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²
        X_salary = salary_df[salary_features]
        y_salary = salary_df[salary_target]
        
        # ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã¨ã‚«ãƒ†ã‚´ãƒªã§ãªã„å¤‰æ•°ã®åˆ†é¡
        salary_cat_features = X_salary.select_dtypes(include=['object', 'category']).columns.tolist()
        salary_num_features = X_salary.select_dtypes(include=['int64', 'float64']).columns.tolist()
        
        # ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ã®ãŸã‚ã®å‰å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
        salary_preprocessor = ColumnTransformer(
            transformers=[
                ('num', StandardScaler(), salary_num_features),
                ('cat', OneHotEncoder(handle_unknown='ignore'), salary_cat_features)
            ]
        )
        
        # ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ - é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
        salary_pipe = Pipeline(steps=[
            ('preprocessor', salary_preprocessor),
            ('regressor', REGRESSION_MODELS[salary_model_type])  # é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
        ])
        
        # ãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²
        X_train_salary, X_test_salary, y_train_salary, y_test_salary = train_test_split(
            X_salary, y_salary, test_size=0.3, random_state=42
        )
        
        # ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’
        with st.spinner(f'{salary_model_type}ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ä¸­...'):
            salary_pipe.fit(X_train_salary, y_train_salary)
        
        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã®äºˆæ¸¬
        y_pred_salary = salary_pipe.predict(X_test_salary)
        
        # ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ï¼ˆR^2ã‚¹ã‚³ã‚¢ã¨å¹³å‡çµ¶å¯¾èª¤å·®ï¼‰
        r2 = r2_score(y_test_salary, y_pred_salary)
        mae = mean_absolute_error(y_test_salary, y_pred_salary)
        
        # çµæœè¡¨ç¤º
        col1, col2 = st.columns(2)
        
        with col1:
            st.write(f"é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«: **{salary_model_type}**")
            st.metric("æ±ºå®šä¿‚æ•° (RÂ²)", f"{r2:.2f}")
            st.metric("å¹³å‡çµ¶å¯¾èª¤å·®", f"${mae:.2f}")
        
        with col2:
            # äºˆæ¸¬ã¨å®Ÿéš›ã®å€¤ã®æ•£å¸ƒå›³
            comparison_df = pd.DataFrame({
                'Actual': y_test_salary,
                'Predicted': y_pred_salary
            })
            
            fig = px.scatter(
                comparison_df, x='Actual', y='Predicted',
                title="äºˆæ¸¬çµ¦ä¸ vs å®Ÿéš›ã®çµ¦ä¸",
                labels={'Actual': 'å®Ÿéš›ã®çµ¦ä¸', 'Predicted': 'äºˆæ¸¬çµ¦ä¸'}
            )
            
            # 45åº¦ç·šï¼ˆç†æƒ³çš„ãªäºˆæ¸¬ç·šï¼‰ã‚’è¿½åŠ 
            fig.add_trace(
                go.Scatter(
                    x=[min(y_test_salary), max(y_test_salary)], 
                    y=[min(y_test_salary), max(y_test_salary)],
                    mode='lines',
                    line=dict(color='red', dash='dash'),
                    name='ç†æƒ³çš„ãªäºˆæ¸¬'
                )
            )
            
            st.plotly_chart(fig, use_container_width=True)
        
        # ç‰¹å¾´é‡é‡è¦åº¦ã®è¡¨ç¤ºï¼ˆãƒ¢ãƒ‡ãƒ«ãŒfeature_importances_å±æ€§ã‚’æŒã¤å ´åˆï¼‰
        if hasattr(salary_pipe.named_steps['regressor'], 'feature_importances_'):
            st.subheader("çµ¦ä¸ã¸ã®å½±éŸ¿è¦å› ")
            
            # ç‰¹å¾´é‡åã®å–å¾—
            if hasattr(salary_pipe.named_steps['preprocessor'], 'get_feature_names_out'):
                feature_names = salary_pipe.named_steps['preprocessor'].get_feature_names_out()
            else:
                # å¤ã„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®scikit-learnã§ã¯åˆ¥ã®æ–¹æ³•ã§å–å¾—
                feature_names = []
                for name, trans, cols in salary_pipe.named_steps['preprocessor'].transformers_:
                    if hasattr(trans, 'get_feature_names_out'):
                        names = trans.get_feature_names_out(cols)
                        feature_names.extend(names)
                    else:
                        feature_names.extend(cols)
            
            # ç‰¹å¾´é‡é‡è¦åº¦ã®å–å¾—
            try:
                importances = salary_pipe.named_steps['regressor'].feature_importances_
                
                # é‡è¦åº¦ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ
                if len(importances) == len(feature_names):
                    feature_importance = pd.DataFrame({
                        'Feature': feature_names,
                        'Importance': importances
                    }).sort_values('Importance', ascending=False).head(15)
                    
                    fig = px.bar(
                        feature_importance, 
                        x='Importance', 
                        y='Feature',
                        orientation='h',
                        title="çµ¦ä¸ã¸ã®å½±éŸ¿è¦å› ï¼ˆä¸Šä½15ï¼‰",
                        color='Importance',
                        color_continuous_scale='Viridis'
                    )
                    fig.update_layout(yaxis={'categoryorder': 'total ascending'})
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    st.warning("ç‰¹å¾´é‡åã¨é‡è¦åº¦ã®æ•°ãŒä¸€è‡´ã—ãªã„ãŸã‚ã€è¡¨ç¤ºã§ãã¾ã›ã‚“ã€‚")
            except Exception as e:
                st.warning(f"é‡è¦åº¦ã®è¡¨ç¤ºä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        elif hasattr(salary_pipe.named_steps['regressor'], 'coef_'):
            # ç·šå½¢ãƒ¢ãƒ‡ãƒ«ã®å ´åˆã¯ä¿‚æ•°ã‚’è¡¨ç¤º
            st.subheader("çµ¦ä¸ã¸ã®å½±éŸ¿è¦å› ï¼ˆä¿‚æ•°ï¼‰")
            
            # ç‰¹å¾´é‡åã®å–å¾—ï¼ˆä¸Šè¨˜ã¨åŒæ§˜ï¼‰
            if hasattr(salary_pipe.named_steps['preprocessor'], 'get_feature_names_out'):
                feature_names = salary_pipe.named_steps['preprocessor'].get_feature_names_out()
            else:
                feature_names = []
                for name, trans, cols in salary_pipe.named_steps['preprocessor'].transformers_:
                    if hasattr(trans, 'get_feature_names_out'):
                        names = trans.get_feature_names_out(cols)
                        feature_names.extend(names)
                    else:
                        feature_names.extend(cols)
            
            try:
                coefs = salary_pipe.named_steps['regressor'].coef_
                
                if len(coefs) == len(feature_names):
                    feature_coefs = pd.DataFrame({
                        'Feature': feature_names,
                        'Coefficient': coefs
                    }).sort_values('Coefficient', ascending=False).head(15)
                    
                    fig = px.bar(
                        feature_coefs, 
                        x='Coefficient', 
                        y='Feature',
                        orientation='h',
                        title="çµ¦ä¸ã¸ã®å½±éŸ¿è¦å› ï¼ˆä¿‚æ•°ä¸Šä½15ï¼‰",
                        color='Coefficient',
                        color_continuous_scale='RdBu'
                    )
                    fig.update_layout(yaxis={'categoryorder': 'total ascending'})
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    st.warning("ç‰¹å¾´é‡åã¨ä¿‚æ•°ã®æ•°ãŒä¸€è‡´ã—ãªã„ãŸã‚ã€è¡¨ç¤ºã§ãã¾ã›ã‚“ã€‚")
            except Exception as e:
                st.warning(f"ä¿‚æ•°ã®è¡¨ç¤ºä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        
        # ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªçµ¦ä¸äºˆæ¸¬
        st.subheader("çµ¦ä¸ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼")
        st.write("å¾“æ¥­å“¡ã®ç‰¹æ€§ã‚’å…¥åŠ›ã—ã¦ã€äºˆæ¸¬ã•ã‚Œã‚‹çµ¦ä¸æ°´æº–ã‚’ç¢ºèªã§ãã¾ã™ã€‚")
        
        col1, col2 = st.columns(2)
        
        with col1:
            sim_job_level = st.selectbox("å½¹è·ãƒ¬ãƒ™ãƒ«", options=[1, 2, 3, 4, 5], index=1, key="sim_job_level")
            sim_age = st.slider("å¹´é½¢", min_value=18, max_value=60, value=35, key="sim_age")
            sim_years_company = st.slider("å‹¤ç¶šå¹´æ•°", min_value=0, max_value=40, value=5, key="sim_years_company")
            sim_total_working = st.slider("ç·åŠ´åƒçµŒé¨“å¹´æ•°", min_value=0, max_value=40, value=10, key="sim_total_working")
            sim_performance = st.selectbox("æ¥­ç¸¾è©•ä¾¡", options=[1, 2, 3, 4], index=2, key="sim_performance")
        
        with col2:
            sim_department = st.selectbox("éƒ¨é–€", options=df['Department'].unique(), key="sim_department")
            sim_job_role = st.selectbox("è·ç¨®", options=df['JobRole'].unique(), key="sim_job_role")
            sim_education = st.selectbox("æ•™è‚²ãƒ¬ãƒ™ãƒ«", options=[1, 2, 3, 4, 5], index=2, key="sim_education")
            sim_education_field = st.selectbox("å°‚é–€åˆ†é‡", options=df['EducationField'].unique(), key="sim_education_field")
            sim_gender = st.selectbox("æ€§åˆ¥", options=df['Gender'].unique(), key="sim_gender")
        
        # äºˆæ¸¬ç”¨ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ
        salary_prediction_data = pd.DataFrame({
            'JobLevel': [sim_job_level],
            'Age': [sim_age],
            'YearsAtCompany': [sim_years_company],
            'TotalWorkingYears': [sim_total_working],
            'Department': [sim_department],
            'JobRole': [sim_job_role],
            'Education': [sim_education],
            'EducationField': [sim_education_field],
            'PerformanceRating': [sim_performance],
            'Gender': [sim_gender]
        })
        
        # çµ¦ä¸äºˆæ¸¬
        predicted_salary = salary_pipe.predict(salary_prediction_data)[0]
        
        # åŒã˜è·ç¨®ã¨å½¹è·ã®å¹³å‡çµ¦ä¸ã‚’å–å¾—
        peer_avg_salary = df[(df['JobRole'] == sim_job_role) & 
                            (df['JobLevel'] == sim_job_level)]['MonthlyIncome'].mean()
        
        # çµæœã®è¡¨ç¤º
        st.subheader("çµ¦ä¸äºˆæ¸¬çµæœ")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.metric("äºˆæ¸¬ã•ã‚Œã‚‹æœˆå", f"${predicted_salary:,.2f}")
            st.metric("å¹´åæ›ç®—", f"${predicted_salary * 12:,.2f}")
        
        with col2:
            peer_comparison = predicted_salary - peer_avg_salary
            peer_pct = (peer_comparison / peer_avg_salary) * 100
            
            st.metric(
                "åŒã˜è·ç¨®ãƒ»å½¹è·ã¨ã®æ¯”è¼ƒ",
                f"${predicted_salary - peer_avg_salary:,.2f}",
                f"{peer_pct:+.1f}%"
            )
            
            # å¸‚å ´ä¾¡å€¤ã®è©•ä¾¡
            if peer_pct > 10:
                st.success("å¸‚å ´å¹³å‡ã‚ˆã‚Šé«˜ã„çµ¦ä¸æ°´æº–ã§ã™")
            elif peer_pct < -10:
                st.warning("å¸‚å ´å¹³å‡ã‚ˆã‚Šä½ã„çµ¦ä¸æ°´æº–ã§ã™")
            else:
                st.info("å¸‚å ´å¹³å‡ã«è¿‘ã„çµ¦ä¸æ°´æº–ã§ã™")
        
        # æ˜‡çµ¦ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        st.subheader("æ˜‡çµ¦ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
        
        sim_options = st.multiselect(
            "ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã—ãŸã„å¤‰æ›´ã‚’é¸æŠã—ã¦ãã ã•ã„",
            options=[
                "1æ®µéšæ˜‡é€²",
                "æ¥­ç¸¾è©•ä¾¡ã‚’1ãƒã‚¤ãƒ³ãƒˆä¸Šã’ã‚‹",
                "å‹¤ç¶šå¹´æ•°ãŒ1å¹´å¢—ãˆã‚‹",
                "éƒ¨é–€ç•°å‹•",
                "è·ç¨®å¤‰æ›´"
            ]
        )
        
        if sim_options:
            # å…ƒã®ãƒ‡ãƒ¼ã‚¿ã‚’ã‚³ãƒ”ãƒ¼
            salary_scenario_data = salary_prediction_data.copy()
            scenario_description = []
            
            for option in sim_options:
                if option == "1æ®µéšæ˜‡é€²":
                    if salary_scenario_data['JobLevel'].values[0] < 5:
                        salary_scenario_data['JobLevel'] = salary_scenario_data['JobLevel'] + 1
                        scenario_description.append("å½¹è·ãƒ¬ãƒ™ãƒ«ãŒä¸ŠãŒã‚‹")
                
                elif option == "æ¥­ç¸¾è©•ä¾¡ã‚’1ãƒã‚¤ãƒ³ãƒˆä¸Šã’ã‚‹":
                    if salary_scenario_data['PerformanceRating'].values[0] < 4:
                        salary_scenario_data['PerformanceRating'] = salary_scenario_data['PerformanceRating'] + 1
                        scenario_description.append("æ¥­ç¸¾è©•ä¾¡ãŒå‘ä¸Šã™ã‚‹")
                
                elif option == "å‹¤ç¶šå¹´æ•°ãŒ1å¹´å¢—ãˆã‚‹":
                    salary_scenario_data['YearsAtCompany'] = salary_scenario_data['YearsAtCompany'] + 1
                    salary_scenario_data['TotalWorkingYears'] = salary_scenario_data['TotalWorkingYears'] + 1
                    scenario_description.append("å‹¤ç¶šå¹´æ•°ãŒå¢—ãˆã‚‹")
                
                elif option == "éƒ¨é–€ç•°å‹•":
                    new_dept = st.selectbox(
                        "ç•°å‹•å…ˆã®éƒ¨é–€ã‚’é¸æŠ",
                        options=[d for d in df['Department'].unique() if d != sim_department],
                        key="new_dept"
                    )
                    salary_scenario_data['Department'] = new_dept
                    scenario_description.append(f"{new_dept}éƒ¨é–€ã«ç•°å‹•ã™ã‚‹")
                
                elif option == "è·ç¨®å¤‰æ›´":
                    new_role = st.selectbox(
                        "æ–°ã—ã„è·ç¨®ã‚’é¸æŠ",
                        options=[r for r in df['JobRole'].unique() if r != sim_job_role],
                        key="new_role"
                    )
                    salary_scenario_data['JobRole'] = new_role
                    scenario_description.append(f"{new_role}ã«è·ç¨®å¤‰æ›´ã™ã‚‹")
            
            # å¤‰æ›´å¾Œã®çµ¦ä¸äºˆæ¸¬
            new_predicted_salary = salary_pipe.predict(salary_scenario_data)[0]
            salary_change = new_predicted_salary - predicted_salary
            salary_change_pct = (salary_change / predicted_salary) * 100
            
            # çµæœè¡¨ç¤º
            st.write(f"**ã‚·ãƒŠãƒªã‚ª:** {', '.join(scenario_description)}")
            st.write(f"**å¤‰æ›´å¾Œã®äºˆæ¸¬æœˆå:** ${new_predicted_salary:,.2f}")
            st.write(f"**æœˆåå¤‰åŒ–:** ${salary_change:+,.2f} ({salary_change_pct:+.1f}%)")
            
            # ãƒãƒ¼ãƒãƒ£ãƒ¼ãƒˆã§ã®æ¯”è¼ƒ
            compare_df = pd.DataFrame({
                'ã‚·ãƒŠãƒªã‚ª': ['ç¾åœ¨', 'å¤‰æ›´å¾Œ'],
                'æœˆå': [predicted_salary, new_predicted_salary]
            })
            
            fig = px.bar(
                compare_df, x='ã‚·ãƒŠãƒªã‚ª', y='æœˆå',
                color='ã‚·ãƒŠãƒªã‚ª',
                text_auto='.2f',
                title="çµ¦ä¸å¤‰åŒ–ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"
            )
            
            # ãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¤ºã‚’ä¿®æ­£
            fig.update_traces(
                text=[f"${val:,.2f}" for val in compare_df['æœˆå']],
                textposition='outside'
            )
            st.plotly_chart(fig, use_container_width=True)
    
    with tab3:
        st.header("äººå“¡è¨ˆç”»ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
        st.info("æ³¨: ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦ã„ã¾ã™ã€‚å®Ÿéš›ã®æ„æ€æ±ºå®šã«ã¯è¿½åŠ ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ã§ã™ã€‚")
        
        # éƒ¨é–€é¸æŠ
        selected_dept = st.selectbox(
            "éƒ¨é–€ã‚’é¸æŠ",
            options=df['Department'].unique()
        )
        
        # é¸æŠã—ãŸéƒ¨é–€ã®ãƒ‡ãƒ¼ã‚¿
        dept_df = df[df['Department'] == selected_dept]
        
        # ç¾åœ¨ã®éƒ¨é–€æ§‹æˆã®åˆ†æ
        st.subheader("ç¾åœ¨ã®éƒ¨é–€æ§‹æˆ")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # å½¹è·ãƒ¬ãƒ™ãƒ«åˆ¥ã®äººæ•°
            level_counts = dept_df['JobLevel'].value_counts().sort_index()
            level_counts.index = level_counts.index.map(lambda x: f"ãƒ¬ãƒ™ãƒ« {x}")
            
            fig = px.pie(
                names=level_counts.index,
                values=level_counts.values,
                title=f"{selected_dept}éƒ¨é–€ã®å½¹è·ãƒ¬ãƒ™ãƒ«æ§‹æˆ",
                hole=0.4
            )
            
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            # è·ç¨®åˆ¥ã®äººæ•°
            role_counts = dept_df['JobRole'].value_counts()
            
            fig = px.bar(
                x=role_counts.index,
                y=role_counts.values,
                title=f"{selected_dept}éƒ¨é–€ã®è·ç¨®æ§‹æˆ",
                labels={'x': 'è·ç¨®', 'y': 'äººæ•°'},
                color=role_counts.values,
                color_continuous_scale='Viridis'
            )
            
            fig.update_layout(xaxis_tickangle=-45)
            st.plotly_chart(fig, use_container_width=True)
        
        # å°†æ¥ã®é›¢è·ç‡äºˆæ¸¬
        st.subheader("é›¢è·ç‡äºˆæ¸¬ï¼ˆ1å¹´å¾Œï¼‰")
        
        # é›¢è·ç¢ºç‡ã‚’è¨ˆç®—
        X_dept = dept_df[features].copy()
        dept_attrition_probs = attrition_pipe.predict_proba(X_dept)[:, 1]
        
        # è·ç¨®åˆ¥ã®å¹³å‡é›¢è·ç¢ºç‡
        role_attrition = {}
        for role in dept_df['JobRole'].unique():
            role_idx = dept_df['JobRole'] == role
            if sum(role_idx) > 0:  # è©²å½“è€…ãŒå­˜åœ¨ã™ã‚‹å ´åˆ
                role_attrition[role] = dept_attrition_probs[role_idx].mean()
        
        # é›¢è·ç¢ºç‡ã®å¯è¦–åŒ–
        role_attrition_df = pd.DataFrame({
            'JobRole': list(role_attrition.keys()),
            'AttritionProbability': list(role_attrition.values())
        }).sort_values('AttritionProbability', ascending=False)
        
        fig = px.bar(
            role_attrition_df,
            x='JobRole',
            y='AttritionProbability',
            title=f"{selected_dept}éƒ¨é–€ã®è·ç¨®åˆ¥é›¢è·ç¢ºç‡",
            labels={'AttritionProbability': 'å¹³å‡é›¢è·ç¢ºç‡', 'JobRole': 'è·ç¨®'},
            color='AttritionProbability',
            color_continuous_scale='Reds',
            text_auto='.1%'
        )
        
        fig.update_layout(xaxis_tickangle=-45)
        st.plotly_chart(fig, use_container_width=True)
        
        # äººå“¡è¨ˆç”»ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        st.subheader("äººå“¡è¨ˆç”»ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
        
        # è¨ˆç”»æœŸé–“ã®é¸æŠ
        planning_period = st.slider(
            "è¨ˆç”»æœŸé–“ï¼ˆå¹´ï¼‰",
            min_value=1,
            max_value=5,
            value=3
        )
        
        # æˆé•·ç‡ã®è¨­å®š
        growth_rate = st.slider(
            "å¹´é–“æˆé•·ç‡ (%)",
            min_value=-10,
            max_value=30,
            value=5,
            step=5
        ) / 100
        
        # é›¢è·ç‡ã®èª¿æ•´
        attrition_adjustment = st.slider(
            "é›¢è·ç‡ã®èª¿æ•´ï¼ˆç¾åœ¨ã®äºˆæ¸¬ã«å¯¾ã™ã‚‹å€ç‡ï¼‰",
            min_value=0.5,
            max_value=1.5,
            value=1.0,
            step=0.1
        )
        
        # è·ç¨®ã”ã¨ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿæ–½
        sim_results = []
        
        for role in dept_df['JobRole'].unique():
            # ç¾åœ¨ã®äººæ•°
            current_headcount = sum(dept_df['JobRole'] == role)
            
            # äºˆæ¸¬é›¢è·ç‡
            role_idx = dept_df['JobRole'] == role
            if sum(role_idx) > 0:
                predicted_attrition_rate = dept_attrition_probs[role_idx].mean() * attrition_adjustment
            else:
                predicted_attrition_rate = 0.1  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
            
            # å¹´ã”ã¨ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
            for year in range(1, planning_period + 1):
                # æˆé•·ã«ã‚ˆã‚‹å¿…è¦äººæ•°ã®å¢—åŠ 
                target_headcount = current_headcount * (1 + growth_rate) ** year
                
                # é›¢è·ã«ã‚ˆã‚‹æ¸›å°‘
                expected_attrition = current_headcount * predicted_attrition_rate * year
                
                # å¿…è¦æ¡ç”¨æ•° = ç›®æ¨™äººæ•° - (ç¾åœ¨ã®äººæ•° - é›¢è·äºˆæ¸¬)
                hiring_need = target_headcount - (current_headcount - expected_attrition)
                
                sim_results.append({
                    'Year': year,
                    'JobRole': role,
                    'CurrentHeadcount': current_headcount,
                    'TargetHeadcount': target_headcount,
                    'ExpectedAttrition': expected_attrition,
                    'HiringNeed': hiring_need
                })
        
        # çµæœã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ åŒ–
        sim_df = pd.DataFrame(sim_results)
        
        # å¹´åˆ¥ãƒ»è·ç¨®åˆ¥ã®æ¡ç”¨å¿…è¦æ•°
        hiring_by_year = sim_df.pivot_table(
            index='Year',
            columns='JobRole',
            values='HiringNeed',
            aggfunc='sum'
        ).fillna(0)
        
        # çµæœã®å¯è¦–åŒ–
        st.write("### è·ç¨®åˆ¥ãƒ»å¹´æ¬¡åˆ¥ã®æ¡ç”¨å¿…è¦æ•°")
        
        # ç©ã¿ä¸Šã’æ£’ã‚°ãƒ©ãƒ•
        hiring_long = sim_df.groupby(['Year', 'JobRole'])['HiringNeed'].sum().reset_index()
        
        fig = px.bar(
            hiring_long,
            x='Year',
            y='HiringNeed',
            color='JobRole',
            title="å¹´æ¬¡ãƒ»è·ç¨®åˆ¥ã®å¿…è¦æ¡ç”¨äººæ•°",
            labels={'HiringNeed': 'æ¡ç”¨å¿…è¦æ•°', 'Year': 'è¨ˆç”»å¹´'},
            barmode='stack'
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # è©³ç´°ãªæ¡ç”¨è¨ˆç”»è¡¨
        st.write("### è©³ç´°æ¡ç”¨è¨ˆç”»è¡¨")
        
        # å¹´åˆ¥ã®åˆè¨ˆæ¡ç”¨æ•°
        total_by_year = sim_df.groupby('Year')['HiringNeed'].sum().reset_index()
        total_by_year.columns = ['è¨ˆç”»å¹´', 'åˆè¨ˆæ¡ç”¨å¿…è¦æ•°']
        total_by_year['åˆè¨ˆæ¡ç”¨å¿…è¦æ•°'] = total_by_year['åˆè¨ˆæ¡ç”¨å¿…è¦æ•°'].round().astype(int)
        
        st.dataframe(total_by_year)
        
        # è·ç¨®åˆ¥ã®æ¡ç”¨æˆ¦ç•¥ææ¡ˆ
        high_attrition_roles = role_attrition_df[role_attrition_df['AttritionProbability'] > 0.15]['JobRole'].tolist()
        
        if high_attrition_roles:
            st.warning(f"ä»¥ä¸‹ã®è·ç¨®ã¯é›¢è·ãƒªã‚¹ã‚¯ãŒé«˜ã„ãŸã‚ã€æ¡ç”¨ã¨å®šç€æ–½ç­–ã®ä¸¡æ–¹ã«æ³¨åŠ›ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼š{', '.join(high_attrition_roles)}")
        
        # æ¡ç”¨ã‚³ã‚¹ãƒˆè©¦ç®—
        st.subheader("æ¡ç”¨ã‚³ã‚¹ãƒˆè©¦ç®—")
        
        # è·ç¨®åˆ¥æ¡ç”¨ã‚³ã‚¹ãƒˆè¨­å®š
        st.write("è·ç¨®åˆ¥ã®1äººã‚ãŸã‚Šæ¡ç”¨ã‚³ã‚¹ãƒˆï¼ˆå††ï¼‰ã‚’è¨­å®šã—ã¦ãã ã•ã„ï¼š")
        
        hiring_costs = {}
        col1, col2 = st.columns(2)
        
        roles = list(dept_df['JobRole'].unique())
        half = len(roles) // 2 + len(roles) % 2
        
        for i, role in enumerate(roles):
            with col1 if i < half else col2:
                default_cost = 500000 if "Manager" in role or "Director" in role else 300000
                hiring_costs[role] = st.number_input(
                    f"{role}",
                    min_value=100000,
                    max_value=2000000,
                    value=default_cost,
                    step=50000,
                    key=f"cost_{role}"
                )
        
        # ã‚³ã‚¹ãƒˆè¨ˆç®—
        cost_data = []
        
        for _, row in sim_df.iterrows():
            hiring_cost = hiring_costs.get(row['JobRole'], 300000)
            total_cost = row['HiringNeed'] * hiring_cost
            
            cost_data.append({
                'Year': row['Year'],
                'JobRole': row['JobRole'],
                'HiringNeed': row['HiringNeed'],
                'HiringCost': hiring_cost,
                'TotalCost': total_cost
            })
        
        cost_df = pd.DataFrame(cost_data)
        
        # å¹´åˆ¥ã®ç·æ¡ç”¨ã‚³ã‚¹ãƒˆ
        yearly_cost = cost_df.groupby('Year')['TotalCost'].sum().reset_index()
        
        fig = px.bar(
            yearly_cost,
            x='Year',
            y='TotalCost',
            title="å¹´æ¬¡åˆ¥ã®æ¡ç”¨äºˆç®—",
            labels={'TotalCost': 'æ¡ç”¨ã‚³ã‚¹ãƒˆï¼ˆå††ï¼‰', 'Year': 'è¨ˆç”»å¹´'},
            color='TotalCost',
            color_continuous_scale='Blues',
            text_auto='.0f'
        )
        
        # ãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¤ºã‚’ä¿®æ­£
        fig.update_traces(
            text=[f"Â¥{val:,.0f}" for val in yearly_cost['TotalCost']],
            textposition='outside'
        )
        st.plotly_chart(fig, use_container_width=True)
        
        # è·ç¨®åˆ¥ã®æ¡ç”¨ã‚³ã‚¹ãƒˆ
        role_cost = cost_df.groupby('JobRole')['TotalCost'].sum().reset_index()
        role_cost = role_cost.sort_values('TotalCost', ascending=False)
        
        fig = px.pie(
            role_cost,
            names='JobRole',
            values='TotalCost',
            title="è·ç¨®åˆ¥ã®æ¡ç”¨ã‚³ã‚¹ãƒˆï¼ˆå…¨æœŸé–“ï¼‰",
            hole=0.4
        )
        
        fig.update_traces(texttemplate='Â¥%{value:,.0f}')
        st.plotly_chart(fig, use_container_width=True)
    
    # ãƒ•ãƒƒã‚¿ãƒ¼
    st.markdown("---")
    st.info("ã“ã®ãƒšãƒ¼ã‚¸ã§ã¯ã€æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’æ´»ç”¨ã—ãŸé›¢è·äºˆæ¸¬ã€çµ¦ä¸äºˆæ¸¬ã€ãŠã‚ˆã³äººå“¡è¨ˆç”»ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚"
            "ã‚ˆã‚Šæˆ¦ç•¥çš„ãªäººäº‹æ„æ€æ±ºå®šã®æ”¯æ´ã«ã”æ´»ç”¨ãã ã•ã„ã€‚")